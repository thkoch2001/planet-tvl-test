<html>
  <head>
    <title>Planet TVL</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta name="generator" content="planet-mars">
    <link rel="shortcut icon" href="/favicon.ico">
    <link rel="stylesheet" href="planet.css" type="text/css">
    <link rel="alternate" type="application/xml+atom" title="Planet Haskell Atom Feed" href="atom.xml">
  </head>
  <body>
    <div id="bodydiv">
    <header>
      <h1>Planet TVL</h1>
    </header>
    <div id="maincontainer">
      <main>
        <article>
            <h2 class="entry_header">
              <a href="https://tech.j4m3s.eu/posts/minimal-jre-nixos/">
                7x JVM Reduction: Nix Your Way to Lighter Docker Images
                </a>
            </h2>
            <div class="entry_meta">
              <date>
                <span>11.01.2025 11:14</span>
                </date>
              </div>

            <div class="entry_summary">
                Reducing by 7x the size of the JVM for fun and profit
              </div>
            </article>
        <hr class="entry_sep">
          <article>
            <h2 class="entry_header">
              <a href="https://blog.benjojo.co.uk/post/sfp-experiment-ultra-long-range-toslink">
                Building Ultra Long Range TOSLINK
                </a>
            </h2>
            <div class="entry_meta">
              <date>
                <span>07.01.2025 12:24</span>
                </date>
              </div>

            <div class="entry_summary">
                <h1>Building Ultra Long Range TOSLINK</h1>

<p><img src="https://blog.benjojo.co.uk/asset/FFyEvN2TXy" alt="" /></p>

<p>This post is a textual version of a talk I gave at <a href="https://events.ccc.de/congress/2024/infos/startpage.html">The 38th Chaos Computer Congress</a> at the end of 2018</p>
              </div>
            </article>
        <hr class="entry_sep">
          <article>
            <h2 class="entry_header">
              <a href="https://blog.koch.ro/posts/2025-01-05-epiphany-38c3-sixos-talk.html">
                Epiphany from 38c3 sixos talk
                </a>
            </h2>
            <div class="entry_meta">
              <date>
                <span>05.01.2025 00:00</span>
                </date>
              &mdash; <span class="entry_author">Thomas Koch</span>
              </div>

            <div class="entry_summary">
                <div class="info">
    Posted on January  5, 2025
    
</div>
<div class="info">
    
    Tags: <a title="All pages tagged &#39;debian&#39;." href="/tags/debian.html">debian</a>, <a title="All pages tagged &#39;nix&#39;." href="/tags/nix.html">nix</a>
    
</div>

<p>There are so many new insights from this talk, that I need to pin them down.</p>
<p><a href="https://media.ccc.de/v/38c3-sixos-a-nix-os-without-systemd">sixos: a nix os without systemd</a> by Adam Joseph (<a href="https://events.ccc.de/congress/2024/hub/de/event/sixos-a-nix-os-without-systemd/">Fahrplan</a>)</p>
<p><a href="https://codeberg.org/amjoseph/sixos">sixos</a> is much like <a href="https://nixos.org">NixOS</a> but uses <a href="https://www.skarnet.org/software/s6/overview.html">s6</a> instead of systemd and an alternative configuration mechanism for services called “<a href="https://codeberg.org/amjoseph/infuse.nix">infusion</a>” instead of nixos’ modules. s6 is a set of small tools that together provide the functionality of process supervision, service dependency mangagement and more.</p>
<p>The s6 site provides A LOT of insight about how to do all of this conforming to the UNIX philosophy. Especially new and interesting to me were the bits about “chain loading” and this <a href="https://skarnet.org/lists/supervision/0422.html">rant about systemd</a>. The latter finally convinced me, that systemd is a bad thing and that I should try to get rid of it. - Sorry for being a bit late to the party.</p>
<p>I’ve a dream of creating a replacement for kubernetes. I don’t need such a thing right now, but it would heal some post-traumatic syndroms after two years of kubernetes support. The small and simple tools from s6 together with nix would already cover a lot of ground.</p>
<p>More interesting bits discoverd:</p>
<ul>
<li>“chain loading” aka “<a href="http://www.catb.org/~esr/writings/taoup/html/ch06s06.html">Bernstein chaining</a>” are terms to describe a chain of processes exec’ing into each other. I didn’t know there are names for this. It’s actually so powerful that one can build a programming language on top of it: <a href="https://skarnet.org/software/execline/grammar.html">execline</a>.</li>
<li><a href="https://github.com/illiliti/libudev-zero">libudev-zero</a> - daemonless replacement for libudev
<ul>
<li><a href="https://github.com/illiliti/respectful-software">respectful-software</a> - alternatives to CoCs and CLAs and more good advice</li>
<li><a href="https://kisscommunity.bvnf.space/">KISS Linux Community</a> - I love KISS</li>
</ul></li>
<li><a href="https://www.brain-dump.org/projects/abduco/">abduco</a> - lighter alternative to SCREEN and TMUX</li>
</ul>
<p>This find quote I want to learn by heart:</p>
<blockquote>
<p>“If the users don’t control the program, the program controls the users. With proprietary software, there is always some entity, the “owner” of the program, that controls the program and through it, exercises power over its users. A nonfree program is a yoke, an instrument of unjust power.” — Richard Stallman<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
</blockquote>
<p>There is no hint to any communication channel for discussions about sixos. But Adam pointed to the <a href="https://tvl.fyi">tvl</a> channel on <a href="https://hackint.org">hackint</a> during his talk for people interested in improving Nix and he is actually operator of a channel #six on hackint. He is amjoseph on IRC.</p>
<p>Now I’m just curious whether there is a story behind the slogan “ca-bundle.crt is malware” that Adam had on his shirt during the talk.</p>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p><a href="https://archive.org/details/stallman-programs-controlling-users">https://archive.org/details/stallman-programs-controlling-users</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
              </div>
            </article>
        <hr class="entry_sep">
          <article>
            <h2 class="entry_header">
              <a href="https://leahneukirchen.org/blog/archive/2024/12/merry-christmas.html">
                Merry Christmas!
                </a>
            </h2>
            <div class="entry_meta">
              <date>
                <span>24.12.2024 15:21</span>
                </date>
              &mdash; <span class="entry_author">Leah Neukirchen</span>
              </div>

            <div class="entry_content">
                <p style="margin: 1em; font-weight: bold; text-align: center">
<img src="https://leahneukirchen.org/blog/graphics/xmas2024.gif"
     alt="Animated comic christmas tree with lights and  antlers">
</p>

<p style="margin: 1em; position: relative: top: 10px; font-size: 140%; font-weight: bold; text-align: center">
Frohe Weihnachten, ein schönes Fest, und einen guten Rutsch ins neue Jahr
wünscht euch<br>Leah Neukirchen
</p>

<p style="margin: 1em; font-size: 140%; font-weight: bold; text-align: center">
Merry Christmas and a Happy New Year!
</p>

<p><small>NP: Trembling Bells&#8212;Willows Of Carbeth</small></p>
              </div>
            </article>
        <hr class="entry_sep">
          <article>
            <h2 class="entry_header">
              <a href="https://leahneukirchen.org/blog/archive/2024/12/how-to-properly-shut-down-a-linux-system.html">
                How to properly shut down a Linux system
                </a>
            </h2>
            <div class="entry_meta">
              <date>
                <span>20.12.2024 13:51</span>
                </date>
              &mdash; <span class="entry_author">Leah Neukirchen</span>
              </div>

            <div class="entry_content">
                <p>In a previous post, I discussed <a href="/blog/archive/2022/01/how-to-check-you-re-in-the-initial-pid-namespace.html">how you can determine that you are
pid 1</a>,
the init process, when the system is booting.  Today, we’ll consider
the end of the init process: system shutdown.</p>
<p>If you look into a book on Unix system administration, the classic way
to manually turn off a Unix system contains a few steps:</p>
<ol>
<li>Bring the system to single-user mode (<code>init 1</code> or <code>shutdown</code>).</li>
<li>Unmount all filesystems except for /.</li>
<li>Remount the root file system read-only.</li>
<li>Run <code>sync</code>.</li>
<li>Turn off the system.</li>
</ol>
<p>What step 1 essentially does is is kill all processes (except for pid
1), and spawn a new shell.  (Unix doesn’t have a concept of
“single-user mode” in kernel space.)  This is necessary to orderly
stop all daemons, kill all remaining user processes, and close open
files that would stop step 2 from progressing.</p>
<p>Step 3 is necessary to ensure the root file system is in a consistent
state.  Since we cannot unmount it (we still use it!), remounting it
read-only is the best available way to ensure consistency.</p>
<p>Finally, we flush buffers, and then it’s safe to turn off the machine.</p>
<p>Now, since this is
<a href="https://github.com/leahneukirchen/sabotage/blob/master/KEEP/etc/rc.shutdown">not</a>
<a href="https://github.com/leahneukirchen/ignite/blob/master/ignite/etc/runit/3">my</a>
<a href="https://github.com/void-linux/void-runit/tree/master/shutdown.d">first</a>
rodeo with writing custom init scripts, I’ve implemented these steps a bunch
of times and found out some things which were not obvious.</p>
<p>So let’s see how some of this works in detail.</p>
<h4>Killing all processes</h4>
<p>This sounds easy, but is tricky to get right.  If you are <em>not</em> pid 1,
using <code>kill(-1, SIGTERM)</code> will send SIGTERM to all processes except for
pid 1 <a href="https://github.com/torvalds/linux/blob/e84a3bf7f4aa669c05e3884497774148ac111468/kernel/signal.c#L1567">and itself</a>
(on Linux on the BSDs).  You should then send a SIGCONT to all processes, so
stopped processes will wake up and handle the SIGTERM, too.  Then you
usually wait a bit for their graceful shutdown and run <code>kill(-1, SIGKILL)</code>
to kill the rest.  Only two processes, you and init, should
remain.  The main problem with this is you don’t know when all
processes have exited after the first kill, so there’s necessarily a
delay.</p>
<p>It is therefore better to let pid 1 do the killing and reaping.  Again
we run <code>kill(-1, SIGTERM); kill(-1, SIGCONT)</code>, and then do the usual
reaping an init process should do.  When <code>waitpid</code> fails with ECHILD,
we know there’s no child left over.  Else, after some timeout, you fall
back to sending SIGKILL to the rest, and reap again.</p>
<p>(As a historical aside, Alan Cox <a href="https://mastodon.social/@etchedpixels/113631181839433174">pointed
out</a> that
on Unix V7, wait(2) in pid 1 keeps waiting for itself, since the parent of pid 1
is pid 1 itself.  However all contemporary systems deal with this fine.)</p>
<p>In the real world, you still want a timeout here.  A process could
be stuck in state <code>D</code> and not respond to SIGKILL either.  We still
want to power down at some point and not lock up shutdown due to this.</p>
<h4>Remounting the file system read-only</h4>
<p>On Linux, you do this by calling <code>mount -o remount,ro /</code>
or the equivalent syscall <code>mount(&quot;/&quot;, &quot;/&quot;, &quot;&quot;, MS_REMOUNT | MS_RDONLY, &quot;&quot;)</code>.
This can fail when the “file system is still in use” with error code
EBUSY.</p>
<p>I ran into this EBUSY error a few times before, and lately a lot
during development, and I finally tried to track down why it happens.
Usually, it’s caused by some process that still has a file handle
open, but at this point of shutdown, there’s nothing running anymore
except for our init itself, so how can that fail?</p>
<p>At first I thought it was just some erratic behavior (race condition
etc.), but then I realized I could trigger the error each time I
updated init (which happens a lot when you are testing code…).
However, when I didn’t update init, everything shutdown fine!</p>
<p>Now, I update init in my testing VM like this:</p>
<pre><code>scp leah@10.0.2.2:prj/.../init /bin/init- &amp;&amp; mv /bin/init- /bin/init
</code></pre>
<p>We can’t overwrite <code>/bin/init</code> directly, else we get ETXTBSY.  So we
do the usual dance of atomically renaming the file into the
destination, similar to how package managers do it.</p>
<p>On an inode level, what does this do?  Overwriting the <code>/bin/init</code>
file decrements the <code>st_nlink</code> field, usually to 0, which means the
old file is deleted.  However, as the init binary is still running (of
course), the inode is kept alive.  We can verify this:</p>
<pre><code># stat -L /proc/1/exe
  File: /proc/1/exe
  Size: 193032    	Blocks: 384        IO Block: 4096   regular file
Device: 8,1	Inode: 137195      Links: 0
Access: (0755/-rwxr-xr-x)  Uid: (    0/    root)   Gid: (    0/    root)
Access: 2024-12-19 17:29:21.289000000 +0000
Modify: 2024-12-19 17:29:21.302000000 +0000
Change: 2024-12-20 15:18:14.480000000 +0000
 Birth: 2024-12-19 17:29:21.289000000 +0000
</code></pre>
<p>The link count is zero indeed.</p>
<p>But this causes the file system <a href="https://github.com/torvalds/linux/blob/8faabc041a001140564f718dabe37753e88b37fa/fs/namespace.c#L710">to stay busy</a>,
since it wants to delete the file when it will be closed, so it cannot
be remounted read-only while there are open file handles to deleted files!
(Thanks to Simon Richter for <a href="https://hachyderm.io/@GyrosGeier/113679452571992737">explaining
this</a>.)  This is
also the reason for the occasional shutdown issues I had using
<code>runit</code>—likely the <code>runit</code> binary was updated during the uptime.</p>
<p>I tried many ways to work around this (old posts may suggest we can
perhaps link <code>/proc/1/exe</code> back into a file, but this behavior has been
forbidden in Linux since 2011), but ultimately I think this is a
policy problem and not one of pid 1 itself.  I therefore suggest a
simple workaround that users of other init systems can use as well:
in the startup scripts, after the root filesystem is mounted writable,
we just make a backup link for the currently booted init:</p>
<pre><code>ln -f /sbin/init /sbin/.init.old
</code></pre>
<p>This ensures that even when <code>/sbin/init</code> is overwritten, its link
count doesn’t drop to zero and we don’t block remounting read-only,
preventing a clean shutdown.</p>
<p>That’s it for now, let’s see what other surprises appear in the future.</p>
<p><small>NP: Laura Jane Grace—Punk Rock In Basements</small></p>
              </div>
            </article>
        <hr class="entry_sep">
          <article>
            <h2 class="entry_header">
              <a href="https://fzakaria.com/2024/12/18/faking-incremental-docker-loads.html">
                Faking incremental Docker loads
                </a>
            </h2>
            <div class="entry_meta">
              <date>
                <span>18.12.2024 20:21</span>
                </date>
              </div>

            <div class="entry_content">
                <p>While <a href="https://testcontainers.com/">testcontainers</a> have made it simple to run containers for unit &amp; system tests, they are not well suited for <a href="https://bazel.build/">Bazel</a> as they rely on <code class="language-plaintext highlighter-rouge">docker pull</code> to hydrate the Docker daemon. The pulls rely on tags which may be rewritten and require input from data (i.e, the images themselves) unknown to Bazel, as well as network access.</p>

<!--more-->

<p><code class="language-plaintext highlighter-rouge">rules_oci</code> is a popular Bazel rules library to incorporate Docker (OCI) images into Bazel that can be used to build subsequent images or be passed as depenedencies to targets.</p>

<p>I wrote a small example <a href="https://github.com/fzakaria/bazel-testcontainer-example">https://github.com/fzakaria/bazel-testcontainer-example</a> that demonstrates how you can <em>modify</em> <a href="https://java.testcontainers.org/">testcontainers-java</a> to leverage these images by passing in the <code class="language-plaintext highlighter-rouge">tar.gz</code> of the image as a <code class="language-plaintext highlighter-rouge">data</code> dependency and explicitly loading it at startup.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">java_test</span><span class="p">(</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">"TestContainerExampleTest"</span><span class="p">,</span>
    <span class="n">srcs</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s">"TestContainerExampleTest.java"</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s">":tarball.tar"</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="n">env</span> <span class="o">=</span> <span class="p">{</span><span class="s">"TARBALL_RUNFILE"</span><span class="p">:</span> <span class="s">"$(rlocationpath :tarball.tar)"</span><span class="p">},</span>
    <span class="n">runtime_deps</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s">"@maven//:org_slf4j_slf4j_simple"</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="n">deps</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s">"@bazel_tools//tools/java/runfiles"</span><span class="p">,</span>
        <span class="s">"@maven//:org_testcontainers_testcontainers"</span><span class="p">,</span>
    <span class="p">],</span>
<span class="p">)</span>

<span class="n">tar</span><span class="p">(</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">"layer"</span><span class="p">,</span>
    <span class="n">srcs</span> <span class="o">=</span> <span class="p">[</span><span class="s">"PingService_deploy.jar"</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">oci_image</span><span class="p">(</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">"image"</span><span class="p">,</span>
    <span class="n">base</span> <span class="o">=</span> <span class="s">"@distroless_java"</span><span class="p">,</span>
    <span class="n">entrypoint</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s">"java"</span><span class="p">,</span>
        <span class="s">"-jar"</span><span class="p">,</span>
        <span class="s">"/src/PingService_deploy.jar"</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="n">tars</span> <span class="o">=</span> <span class="p">[</span><span class="s">":layer"</span><span class="p">],</span>
<span class="p">)</span>
</code></pre></div></div>

<p><em>Sounds great?</em> 🙌 … <em>Right?</em> 😕</p>

<p>Turns out if your image is moderately large (&gt;2GiB), an individual upload can take a relatively long time (~30s). This can compound if you have multiple concurrent tests each tryin to upload to the Docker daemon such as in the case in Bazel.</p>

<p>There is <strong>no handshaking</strong> or range-read of the compressed stream, meaning you must send the whole compressed image, which must then be uncompressed and validated for Docker to determine it already had the necessary layers present.</p>

<p>We experienced this with our tests either failing or timing out as each concurrent test tried to upload multi-gigabyte images concurrently.</p>

<p>Turns out, this limitation is documented and known:</p>
<ul>
  <li><a href="https://github.com/docker/buildx/issues/107">docker/buildx/issues/107</a></li>
  <li><a href="https://github.com/bazel-contrib/rules_oci/issues/454">bazel-contrib/rules_oci/issues/454</a></li>
  <li><a href="https://github.com/moby/moby/issues/44369">moby/moby/issues/44369</a></li>
</ul>

<p>❗ <em>There exists no API to query the layers the Docker engine has locally</em>.</p>

<p>For a <em>quick’n’dirty</em> (but effective) workaround I relied on the following before our CI job</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> bazel query <span class="s2">"kind(oci_load, //...)"</span> <span class="se">\</span>
    | xargs <span class="nt">-n</span> 1 <span class="nt">-P</span> 8 <span class="nt">-I</span> target bazel run target
</code></pre></div></div>

<p>It would be great if we didn’t need any invocation prior to a test; are Bazel users left <em>holding the bag</em> ? 🫂</p>

<p>Don’t despair! Turns out we can <strong>fake incrementality</strong> uploads in Docker with a relatively ingenious method. 😭</p>

<blockquote>
  <p>Note: I did not invent this solution. There are other existing prior art, namely:</p>
  <ul>
    <li><a href="https://github.com/bazelbuild/rules_docker/blob/master/container/incremental_load.sh.tpl">bazelbuild/rules_docker/blob/master/container/incremental_load.sh.tpl</a></li>
    <li><a href="https://github.com/aspect-build/bazel-examples/blob/main/oci_python_image/hello_world/app_test.py">aspect-build/bazel-examples/blob/main/oci_python_image/hello_world/app_test.py</a></li>
    <li><a href="https://github.com/datahouse/bazel_buildlib/blob/oss/buildlib/private/docker/src/loadImageToDocker.ts">datahouse/bazel_buildlib/blob/oss/buildlib/private/docker/src/loadImageToDocker.ts
</a></li>
  </ul>
</blockquote>

<p>🪄 The trick is that we will upload Docker images with <strong>metadata but no actual layer data</strong>, and incrementally include the layer only if it’s required.</p>

<p><img src="/assets/images/piccard_docker_image.jpg" alt="Piccard graphic" /></p>

<p>Let’s break it down.</p>

<ol>
  <li>
    <p>A Docker image, which is different than the OCI format, is a <em>tar</em> file (or <em>tar.gz</em>) with a file <code class="language-plaintext highlighter-rouge">manifest.json</code> that dictates the files that should be present within the archive.</p>

    <p>I’ve shortened the sha256 in the below example.</p>

    <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w"> </span><span class="p">[{</span><span class="w">
 </span><span class="nl">"Config"</span><span class="p">:</span><span class="w"> </span><span class="s2">"blobs/sha256/8f73f04"</span><span class="p">,</span><span class="w">
 </span><span class="nl">"RepoTags"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w"> </span><span class="s2">"example:0.1"</span><span class="w"> </span><span class="p">],</span><span class="w">
 </span><span class="nl">"Layers"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
   </span><span class="s2">"blobs/sha256/6dd6992"</span><span class="p">,</span><span class="w">
   </span><span class="s2">"blobs/sha256/41e9df2"</span><span class="p">,</span><span class="w">
   </span><span class="s2">"blobs/sha256/3ec46cfe"</span><span class="p">,</span><span class="w">
   </span><span class="s2">"blobs/sha256/1225e888"</span><span class="p">,</span><span class="w">
 </span><span class="p">]}]</span><span class="w">
</span></code></pre></div>    </div>
  </li>
  <li>
    <p>Although our metadata outlines <em>4 different layers</em>, we can can omit the actual layer data.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="o">&gt;</span> <span class="nb">tar </span>tf testimage.tar.gz | tree <span class="nt">--fromfile</span> <span class="nb">.</span>
 <span class="nb">.</span>
 ├── blobs
 │   └── sha256
 │       └── 8f73f04
 └── manifest.json
</code></pre></div>    </div>
  </li>
  <li>
    <p>If we try to upload this image, if the local daemon has all the layers already present, the upload will succeed <strong>despite us not including any actual layers</strong>.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="o">&gt;</span> docker load &lt; testimage.tar.gz
 Loaded image: example:0.1
</code></pre></div>    </div>
  </li>
  <li>
    <p>If a layer is missing locally, we detect it via the error response and subsequently include it in
the archive and re-upload it.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="o">&gt;</span> docker load &lt; testimage.tar.gz
 open /var/lib/docker/tmp/docker-import-2494045611/blobs/sha256/6dd6992:
 no such file or directory
</code></pre></div>    </div>
  </li>
</ol>

<p>We can perform these steps incrementally by adding each layer one-at-a-time which looks like the following
in pseudocode.</p>

<blockquote>
  <p>⚠️ It’s important to also restrict the <code class="language-plaintext highlighter-rouge">diff_ids</code> which represent a validation of the state of the container
when the layers are applied.</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">function</span> <span class="n">incremental_load</span><span class="p">(</span><span class="n">client</span><span class="p">,</span> <span class="n">repo_tag</span><span class="p">,</span> <span class="n">base_path</span><span class="p">):</span>
<span class="s">"""Incrementally loads a Docker image."""</span>

<span class="c1"># Parse image index
</span><span class="n">index_path</span> <span class="o">=</span> <span class="n">base_path</span> <span class="o">+</span> <span class="s">"/index.json"</span>
<span class="n">index</span> <span class="o">=</span> <span class="n">from_json</span><span class="p">(</span><span class="n">index_path</span><span class="p">)</span>

<span class="c1"># Parse manifest and config
</span><span class="n">manifest_digest</span> <span class="o">=</span> <span class="n">index</span><span class="p">.</span><span class="n">manifests</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">digest</span>
<span class="n">manifest</span> <span class="o">=</span> <span class="n">from_json</span><span class="p">(</span><span class="n">blob</span><span class="p">(</span><span class="n">base_path</span><span class="p">,</span> <span class="n">manifest_digest</span><span class="p">))</span>
<span class="n">full_config</span> <span class="o">=</span> <span class="n">from_json</span><span class="p">(</span><span class="n">blob</span><span class="p">(</span><span class="n">base_path</span><span class="p">,</span> <span class="n">manifest</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">digest</span><span class="p">))</span>
<span class="n">config_blob_path</span> <span class="o">=</span> <span class="n">blob_path</span><span class="p">(</span><span class="n">manifest</span><span class="p">.</span><span class="n">config</span><span class="p">)</span>

<span class="n">missing_layer</span> <span class="o">=</span> <span class="n">null</span>
<span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">manifest</span><span class="p">.</span><span class="n">layers</span><span class="p">):</span>
  <span class="c1"># Try uploading each layer one at a time
</span>  <span class="n">layers</span> <span class="o">=</span> <span class="n">manifest</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>

  <span class="c1"># Create partial config
</span>  <span class="n">tmp_config</span> <span class="o">=</span> <span class="n">full_config</span><span class="p">.</span><span class="n">clone</span><span class="p">().</span><span class="n">rootfs</span><span class="p">.</span><span class="n">diffIds</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>

  <span class="c1"># Create partial image tar
</span>  <span class="n">image</span> <span class="o">=</span> <span class="n">create_image_tar</span><span class="p">(</span><span class="n">base_path</span><span class="p">,</span> <span class="n">config_blob_path</span><span class="p">,</span>
                           <span class="n">tmp_config</span><span class="p">,</span> <span class="n">layers</span><span class="p">,</span> <span class="n">missing_layer</span><span class="p">)</span>

  <span class="c1"># Upload partial image, and parse out if any layer is needed
</span>  <span class="n">missing_layer</span> <span class="o">=</span> <span class="n">upload_image</span><span class="p">(</span><span class="n">client</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>

  <span class="c1"># No missing layer, move onto the next one
</span>  <span class="k">if</span> <span class="n">missing_layer</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="c1"># Missing layer found, try again but this time upload it!
</span>    <span class="k">pass</span>

<span class="c1"># Upload full image
</span><span class="n">full_image</span> <span class="o">=</span> <span class="n">create_image_tar</span><span class="p">(</span><span class="n">base_path</span><span class="p">,</span> <span class="n">config_blob_path</span><span class="p">,</span>
                              <span class="n">full_config</span><span class="p">,</span> <span class="n">manifest</span><span class="p">.</span><span class="n">layers</span><span class="p">)</span>
<span class="n">upload_image</span><span class="p">(</span><span class="n">client</span><span class="p">,</span> <span class="n">full_image</span><span class="p">)</span>
</code></pre></div></div>

<blockquote>
  <p>If you are interested in the equivalent Java code let me know and I can publish it.</p>
</blockquote>

<p>With this approach you can now have <strong>incremental Docker uploads</strong>! Huzzah! 🙌🏽</p>

<p>Problem solved? Sorta? Well….not actually. If the images you are uploading contain
individual large layers, perhaps they were squashed, we are back to square one.</p>

<p>Here we see an example image whose single layer is 1.28GiB.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> docker image <span class="nb">history </span>bad_example:0.1 <span class="nt">--human</span> <span class="se">\</span>
                    <span class="nt">--format</span> <span class="s1">'table '</span> | <span class="nb">head
</span>SIZE
0B
0B
7.87kB
0B
1.28GB
0B
0B
0B
0B
</code></pre></div></div>

<h3 id="wheres-time-spent">Where’s time spent?</h3>
<p>At this point you have to improve the image by seggregating the data into more multiple layers or continue to upload it outside of the Bazel context.</p>

<p>🕵️ I would like to dive deeper and understand why the uploads completely stall.</p>

<p>The relevant code in Docker <a href="https://github.com/moby/moby/blob/0d53725a7f8abb0b75961806da252f31155cb813/image/tarexport/load.go#L33">can be found here</a>.</p>

<p>Quick benchmarks done on my M3 Pro MacBook demonstrate it takes ~35-45 seconds to gzip a 2GiB file.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> <span class="nb">time </span>docker save bad_example:0.1 | <span class="nb">gzip</span> <span class="o">&gt;</span> test.tar.gz
docker save bad_example:0.1  0.49s user 2.49s system 6% cpu 44.843 total
<span class="nb">gzip</span> <span class="o">&gt;</span> test.tar.gz  36.72s user 0.48s system 82% cpu 44.842 total
</code></pre></div></div>

<p>Uploading the image seems to take ~15 seconds</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> <span class="nb">time </span>docker load &lt; test.tar.gz
75cc828c731c: Loading layer <span class="o">[==================================================&gt;]</span>  102.1MB/102.1MB
20ebbf9559c4: Loading layer <span class="o">[==================================================&gt;]</span>  552.9MB/552.9MB
1049fe83b46b: Loading layer <span class="o">[==================================================&gt;]</span>  10.14MB/10.14MB
b4a5b99cb981: Loading layer <span class="o">[==================================================&gt;]</span>  331.8kB/331.8kB
a9e2a3aa94a5: Loading layer <span class="o">[==================================================&gt;]</span>  39.34MB/39.34MB
93ca7c014948: Loading layer <span class="o">[==================================================&gt;]</span>  6.144kB/6.144kB
71d670ccc47b: Loading layer <span class="o">[==================================================&gt;]</span>  4.608kB/4.608kB
1838b4d29208: Loading layer <span class="o">[==================================================&gt;]</span>  2.048kB/2.048kB
0d9eb9b0c742: Loading layer <span class="o">[==================================================&gt;]</span>   2.56kB/2.56kB
c68e52b834e4: Loading layer <span class="o">[==================================================&gt;]</span>  1.284GB/1.284GB
749f1729f609: Loading layer <span class="o">[==================================================&gt;]</span>   16.9kB/16.9kB
Loaded image: bad_example:0.1
docker load &lt; test.tar.gz  0.38s user 1.62s system 13% cpu 14.565 total
</code></pre></div></div>

<p>That means creating the archive  and uploading it can take ~1 minute of test execution time. This problem seems to compound with multiple archives created and uploaded; more research is needed to know if the bottleneck is the Docker daemon itself (a global lock?) or the I/O of the disk.</p>
              </div>
            </article>
        <hr class="entry_sep">
          <article>
            <h2 class="entry_header">
              <a href="https://blog.benjojo.co.uk/post/rfc-in-38-simple-steps">
                The "simple" 38 step journey to getting an RFC
                </a>
            </h2>
            <div class="entry_meta">
              <date>
                <span>05.12.2024 10:43</span>
                </date>
              </div>

            <div class="entry_summary">
                <h1>The &ldquo;simple&rdquo; 38 step journey to getting an RFC</h1>

<p>The Internet is built on the mutual understanding of network protocols and practices, and most of those protocols are defined using Request For Comments (RFC) or Best Common Practices (BCP) documents.</p>
              </div>
            </article>
        <hr class="entry_sep">
          <article>
            <h2 class="entry_header">
              <a href="https://leahneukirchen.org/blog/archive/2024/11/time-series-based-monitoring-in-very-heterogeneous-environments.html">
                Time series based monitoring in very heterogeneous environments
                </a>
            </h2>
            <div class="entry_meta">
              <date>
                <span>29.11.2024 18:49</span>
                </date>
              &mdash; <span class="entry_author">Leah Neukirchen</span>
              </div>

            <div class="entry_content">
                <p>For the last few years, I have built a centralized monitoring system
based on <a href="https://prometheus.io/">Prometheus</a> that gathers various
metrics across my whole private fleet of servers.</p>
<p>Since writing Prometheus exporters is rather simple, I have written
some of them myself:</p>
<ul>
<li><a href="https://github.com/leahneukirchen/lywsd03mmc-exporter/">lywsd03mmc-exporter</a>,
a Prometheus exporter for the LYWSD03MMC BLE
thermometer which monitors my flat’s temperature and air humidity
(as well as when to replace the batteries).</li>
<li><a href="https://leahneukirchen.org/dotfiles/bin/card10-bme680-exporter.rb">card10-bme680-exporter</a>,
which accesses the environmental sensor of the <a href="https://card10.badge.events.ccc.de/">card10</a>
via serial port for measuring air quality.</li>
<li><a href="https://leahneukirchen.org/dotfiles/bin/tab-exporter.rb">tab-exporter</a>
which exports the number of Firefox tabs I have open
(this needs <a href="https://git.yori.cc/yorick/dotfiles/src/branch/master/pkgs/countfftabs">countfftabs</a>).</li>
<li>I also forked and improved <a href="https://github.com/leahneukirchen/nano-exporter/">nano-exporter</a>,
a very lightweight and zero-dependency Linux version of <a href="https://github.com/prometheus/node_exporter">node_exporter</a>.</li>
</ul>
<p>Additionally I use the following pre-made exporters:</p>
<ul>
<li><a href="https://github.com/prometheus/node_exporter">node_exporter</a> for monitoring FreeBSD and some other hosts.</li>
<li><a href="https://github.com/martin-helmich/prometheus-nginxlog-exporter">prometheus-nginxlog-exporter</a> for web server metrics.</li>
<li><a href="https://github.com/SuperQ/chrony_exporter">chrony_exporter</a> for monitoring my NTP server.</li>
<li><a href="https://github.com/brendanbank/gpsd-prometheus-exporter">gpsd-prometheus-exporter</a> for monitoring the GPS signal on my NTP server.</li>
<li><a href="https://github.com/SuperQ/smokeping_prober">smokeping_prober</a> for detecting network outages and other problems.</li>
<li><a href="https://github.com/google/mtail">mtail</a> for extracting metrics out of Postfix logs and other log files.</li>
</ul>
<p>As you can see, this is quite a lot of different exporters running on
different hosts.</p>
<p>A few months ago I decided to rebuild the centralized metrics server on
top of <a href="https://victoriametrics.com/">VictoriaMetrics</a> and with proper
access control.</p>
<p>Why VictoriaMetrics? I tried it for a bit and it seems to use less RAM
and less storage while supporting long term storage nicely.  It also has
better mechanisms for importing and exporting data than Prometheus.</p>
<h5>Setting up VictoriaMetrics</h5>
<p>Setting up <code>victoria-metrics</code> is very easy.  I run it like this:</p>
<pre><code>victoria-metrics -enableTCP6 \
  -storageDataPath=/srv/victoria-metrics \
  -retentionPeriod=99y \
  -httpListenAddr=127.0.0.1:8428 \
  -selfScrapeInterval=20s \
  -promscrape.config /usr/local/etc/prometheus/prometheus.yaml
</code></pre>
<p>Note that you need to enable IPv6 manually all the time.</p>
<p>The <code>prometheus.yaml</code> file is compatible with stock Prometheus.</p>
<p>I then use Grafana to connect to it, using the Prometheus protocol.</p>
<h5>Scraping non-public endpoints</h5>
<p>I don’t consider most of above metrics to be super private, but they
certainly leak metadata (e.g. am I at home or not, how much mail do I
get) so I don’t want to publish them on the net accessible to everyone
that finds them.</p>
<p>Since Prometheus mainly favors a pull based model, we need to figure
out ways to protect the data.</p>
<p>“Obvious” solutions like using mTLS or a maintenance VPN would require
reconfiguring many machines and were deemded too much effort.</p>
<p>Essentially, I found three solutions that I will describe in detail:</p>
<h4>Hiding metrics behind existing web servers</h4>
<p>This is the easiest mechanism, when your host already runs a web
server: simply use it as a proxy for the metrics, and filter access by
IP address or Basic Auth.  Since most webservers have HTTPS today
already, you get encryption for free.</p>
<p>A simple nginx configuration to do this would be:</p>
<pre><code>location /metrics {
        proxy_http_version 1.1;
        proxy_pass http://127.0.0.1:9100/metrics;
        access_log off;
        allow 127.0.0.1;
        allow ...;
        deny all;
}
</code></pre>
<p>You need to configure the metrics exporter to only listen on localhost.</p>
<h5>Reverse SSH tunnelling</h5>
<p>This is a quite elegant solution that provides encryption, flexible
configuration, and can be used when the scrape target doesn’t have a
public IP address.  OpenSSH provides the <code>-R</code> flag to do reverse port
forwarding, but most people don’t know it also can be used to run a
reverse SOCKS proxy!</p>
<p>For this, I create a separate Unix user on scrape target and server,
and assign it a SSH key.  Then, the target runs:</p>
<pre><code>ssh -o ServerAliveInterval=15 -o ExitOnForwardFailure=yes -R8083 server.example.com -NT
</code></pre>
<p>You should run this using <a href="https://smarden.org/runit/">service supervision</a>
so it tries to reconnect on network failures.</p>
<p>On the server side, you restrict access to only open a port
using <code>/etc/ssh/authorized_keys/scrape-user</code>:</p>
<pre><code>restrict,port-forwarding,permitlisten=&quot;8083&quot; ssh-ed25519 ....
</code></pre>
<p>Then, the server can use port 8083 as a SOCKS proxy to access the
network of the scrape target directly!  So you can write a scrape config like:</p>
<pre><code>  - job_name: 'nano-exporter-hecate'
    proxy_url: 'socks5://127.0.0.1:8083'
    static_configs:
    - targets: ['127.0.0.1:9100']
      labels:
        instance: 'hecate.home.vuxu.org:9100'
    - targets: ['10.0.0.119:9100']
      labels:
        instance: 'leto.home.vuxu.org:9100'
</code></pre>
<p>Here, we use a host in my home network that is always on, and can also
safely scrape other hosts in the same LAN.
(Note that the IP addresses in <code>targets</code> are resolved relative to the SSH client.)</p>
<h5>Pushing with vmagent</h5>
<p>I used the SSH approach for my notebook as well, but there’s the
problem that we lose data when there’s no Internet connection
available.  I have thus moved my notebook to a solution using
<a href="https://docs.victoriametrics.com/vmagent/"><code>vmagent</code></a>, which is
included with VictoriaMetrics.</p>
<p><code>vmagent</code> does scrape metrics just like VictoriaMetrics (and also
supports all other metrics protocols, but I don’t use them), but it
simply forwards everything via the Prometheus remote write protocol,
and locally buffers data if it can’t forward the metrics currently.</p>
<p>On the server side, we need to provide access to the remote write
protocol.  Since VictoriaMetrics operates without internal access
control, we can use the
<a href="https://docs.victoriametrics.com/vmauth/"><code>vmauth</code></a> gateway to
implement Basic Auth over TLS.  (Again, you can use an existing HTTPS
server and proxy it, but in this case I don’t have a HTTPS server on
the metrics host.)</p>
<p><code>vmauth</code> needs some configuration.  First, we create a self-signed
certificate (Let’s Encrypt support is limited to the commercial
version of VictoriaMetrics unfortunately):</p>
<pre><code>openssl req -x509 -newkey ed25519 \
	-keyout /usr/local/etc/vmauth/key.pem \
	-out /usr/local/etc/vmauth/cert.pem \
	-sha256 -days 3650 -nodes -subj &quot;/CN=server.example.org&quot; \
	-addext &quot;subjectAltName = DNS:server.example.org&quot;
</code></pre>
<p>I then run it as:</p>
<pre><code>vmauth -enableTCP6 \
  -tls \
  -tlsCertFile=/usr/local/etc/vmauth/cert.pem \
  -tlsKeyFile=/usr/local/etc/vmauth/key.pem \
  -reloadAuthKey=secret \
  -flagsAuthKey=secret \
  -metricsAuthKey=secret \
  -pprofAuthKey=secret \
  -auth.config=/usr/local/etc/vmauth/vmauth.yaml
</code></pre>
<p>(I think it’s unfortunate that we need to add auth-keys now,
as internal and forwarded API are exposed on the same port…)</p>
<p>The <code>vmauth.yaml</code> configures who can access:</p>
<pre><code>users:
- username: &quot;client&quot;
  password: &quot;evenmoresecret&quot;
  url_prefix: &quot;http://localhost:8428/&quot;
</code></pre>
<p>Here, <code>localhost:8428</code> is the VictoriaMetrics instance.</p>
<p>Finally, on the scrape target we can now run <code>vmagent</code>:</p>
<pre><code>vmagent -enableTCP6 \
        -promscrape.config=/etc/vmagent/promscrape.yml \
        -httpListenAddr=127.0.0.1:8429 \
        -remoteWrite.url=https://server.example.org:8427/api/v1/write \
        -remoteWrite.label=vmagent=myhostname \
        -remoteWrite.retryMinInterval=30s \
        -remoteWrite.basicAuth.username=client \
        -remoteWrite.basicAuth.passwordFile=/etc/vmagent/passwd \
        -remoteWrite.tlsCAFile=/etc/vmagent/cert.pem
</code></pre>
<p>The <code>cert.pem</code> is copied from the server, the password is stored in <code>/etc/vmagent/passwd</code>.</p>
<p>Note that the <code>vmagent</code> instance is configured locally, so we can again
scrape targets that are only reachable from it.  We also can adjust
the scrape targets without having to touch the metrics server itself.</p>
<p><small>NP: Godspeed You! Black Emperor—Broken Spires At Dead Kapital</small></p>
              </div>
            </article>
        <hr class="entry_sep">
          <article>
            <h2 class="entry_header">
              <a href="https://fzakaria.com/2024/11/28/bazel-knowledge-protobuf-is-the-worst-when-it-should-be-the-best.html">
                Bazel Knowledge: Protobuf is the worst when it should be the best
                </a>
            </h2>
            <div class="entry_meta">
              <date>
                <span>28.11.2024 22:07</span>
                </date>
              </div>

            <div class="entry_content">
                <p>Bazel has always had support for <a href="https://protobuf.dev/">protocol buffers (protobuf)</a> since the beginning.
Both being a Google product, one would think that their integration would be seamless and the best experience.
Unfortunately, it’s some of the worst part of the user experience with Bazel I’ve found. 😔</p>

<!--more-->

<p>Let’s start with the basics; <em>What rule should I adopt for protobufs?</em></p>

<p>Well first I Google <em>“Bazel protobuf”</em> and land on the <a href="https://bazel.build/reference/be/protocol-buffer">protobuf reference page</a> for Bazel
which states:</p>

<blockquote>
  <p>If using Bazel, please load the rule from https://github.com/bazelbuild/rules_proto.</p>
</blockquote>

<p>One may think the sensible <a href="https://github.com/bazelbuild/rules_proto">rules_proto</a> is a good starting
point but the <em>README.md</em> states:</p>

<blockquote>
  <p>This repository is <strong>deprecated</strong>…we decided to move the implementation of
the rules together with proto compiler into protobuf repository.</p>
</blockquote>

<p>OK…🤔</p>

<p>Let’s go check <a href="https://github.com/protocolbuffers/protobuf">protobuf</a>.</p>

<p>The <em>README.md</em> claims one can install one of two ways by inserting the following
into your <em>MODULE.bazel</em> without much explanation as to the difference. 🤷‍♂️</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bazel_dep</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="s">"protobuf"</span><span class="p">,</span> <span class="n">version</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">VERSION</span><span class="o">&gt;</span><span class="p">)</span>
<span class="c1">#
# or
#
</span><span class="n">bazel_dep</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="s">"protobuf"</span><span class="p">,</span> <span class="n">version</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">VERSION</span><span class="o">&gt;</span><span class="p">,</span>
          <span class="n">repo_name</span> <span class="o">=</span> <span class="s">"com_google_protobuf"</span><span class="p">)</span>
</code></pre></div></div>

<p>I decide to audit the source to see what’s going on.
You quickly land on the <a href="https://github.com/protocolbuffers/protobuf/blob/cbecd9d2fa1d7187cca63a8c18838e87a4f613ec/bazel/private/bazel_proto_library_rule.bzl#L239">rule definition</a>
for <em>proto_library</em> and see the following documentation for the rule. 🤦</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">proto_library</span> <span class="o">=</span> <span class="n">rule</span><span class="p">(</span>
    <span class="n">_proto_library_impl</span><span class="p">,</span>
    <span class="c1"># TODO: proto_common docs are missing
</span>    <span class="c1"># TODO: ProtoInfo link doesn't work and docs are missing
</span>    <span class="n">doc</span> <span class="o">=</span> <span class="s">"""
&lt;p&gt;If using Bazel, please load the rule from
&lt;a href="https://github.com/bazelbuild/rules_proto"&gt;
https://github.com/bazelbuild/rules_proto&lt;/a&gt;.
</span></code></pre></div></div>

<p>Where is the <strong>protoc</strong> (protobuf compiler) ultimately coming from for the rule?
I notice these interesting snippets in the rule.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">toolchains</span><span class="p">.</span><span class="n">if_legacy_toolchain</span><span class="p">({</span>
        <span class="s">"_proto_compiler"</span><span class="p">:</span> <span class="n">attr</span><span class="p">.</span><span class="n">label</span><span class="p">(</span>
            <span class="n">cfg</span> <span class="o">=</span> <span class="s">"exec"</span><span class="p">,</span>
            <span class="n">executable</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
            <span class="n">allow_files</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
            <span class="n">default</span> <span class="o">=</span> <span class="n">configuration_field</span><span class="p">(</span><span class="s">"proto"</span><span class="p">,</span> <span class="s">"proto_compiler"</span><span class="p">),</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">_incompatible_toolchain_resolution</span> <span class="o">=</span>
    <span class="nb">getattr</span><span class="p">(</span><span class="n">native_proto_common</span><span class="p">,</span>
            <span class="s">"INCOMPATIBLE_ENABLE_PROTO_TOOLCHAIN_RESOLUTION"</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_if_legacy_toolchain</span><span class="p">(</span><span class="n">legacy_attr_dict</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">_incompatible_toolchain_resolution</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">legacy_attr_dict</span>
</code></pre></div></div>

<p>Turns out that <em>INCOMPATIBLE_ENABLE_PROTO_TOOLCHAIN_RESOLUTION</em> is set from the command line <a href="https://bazel.build/reference/command-line-reference#flag--incompatible_enable_proto_toolchain_resolution">ref</a>.</p>

<blockquote>
  <p>–[no]incompatible_enable_proto_toolchain_resolution default: “false”
If true, proto lang rules define toolchains from protobuf repository.
Tags: loading_and_analysis, incompatible_change</p>
</blockquote>

<p>I don’t have that in my <code class="language-plaintext highlighter-rouge">.bazelrc</code> so let’s ignore it.
That means our <code class="language-plaintext highlighter-rouge">_proto_compiler</code> is coming from <code class="language-plaintext highlighter-rouge">configuration_field("proto", "proto_compiler")</code>.</p>

<p>You then search the <a href="https://github.com/bazelbuild/bazel/blob/a3f0cebd35989e120d5cdaf7882b4e93df82e590/src/main/java/com/google/devtools/build/lib/rules/proto/ProtoConfiguration.java#L68">bazelbuild/bazel</a> source to find where it’s defined.</p>
<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@Option</span><span class="o">(</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">"proto_compiler"</span><span class="o">,</span>
    <span class="n">defaultValue</span> <span class="o">=</span> <span class="nc">ProtoConstants</span><span class="o">.</span><span class="na">DEFAULT_PROTOC_LABEL</span><span class="o">,</span>
    <span class="n">converter</span> <span class="o">=</span> <span class="nc">CoreOptionConverters</span><span class="o">.</span><span class="na">LabelConverter</span><span class="o">.</span><span class="na">class</span><span class="o">,</span>
    <span class="n">documentationCategory</span> <span class="o">=</span> <span class="nc">OptionDocumentationCategory</span><span class="o">.</span><span class="na">UNCATEGORIZED</span><span class="o">,</span>
    <span class="n">effectTags</span> <span class="o">=</span> <span class="o">{</span><span class="nc">OptionEffectTag</span><span class="o">.</span><span class="na">AFFECTS_OUTPUTS</span><span class="o">,</span> <span class="nc">OptionEffectTag</span><span class="o">.</span><span class="na">LOADING_AND_ANALYSIS</span><span class="o">},</span>
    <span class="n">help</span> <span class="o">=</span> <span class="s">"The label of the proto-compiler."</span><span class="o">)</span>
<span class="kd">public</span> <span class="nc">Label</span> <span class="n">protoCompiler</span><span class="o">;</span>
</code></pre></div></div>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// The flags need to point to @bazel_tools, because this is a canonical repo</span>
<span class="c1">// name when either bzlmod or WORKSPACE mode is used.</span>
<span class="cm">/** Default label for proto compiler.*/</span>
<span class="kd">public</span> <span class="kd">static</span> <span class="kd">final</span> <span class="nc">String</span> <span class="no">DEFAULT_PROTOC_LABEL</span>
        <span class="o">=</span> <span class="s">"@bazel_tools//tools/proto:protoc"</span><span class="o">;</span>
</code></pre></div></div>

<p>Chasing down the ultimate target in the defining <a href="https://github.com/bazelbuild/bazel/blob/3d528ac42cce1a71d8358b57cdbe4b3e743bd307/tools/proto/BUILD#L15">BUILD</a>
file you discover it’s an alias to <code class="language-plaintext highlighter-rouge">"@com_google_protobuf//:protoc"</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Those aliases are needed to resolve the repository name correctly in both
# bzlmod and WORKSPACE mode. They are resolved in the namespace of MODULE.tools
</span>
<span class="n">alias</span><span class="p">(</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">"protoc"</span><span class="p">,</span>
    <span class="n">actual</span> <span class="o">=</span> <span class="s">"@com_google_protobuf//:protoc"</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div></div>

<p>😲 So we discovered why <code class="language-plaintext highlighter-rouge">com_google_protobuf</code> may want to be the <code class="language-plaintext highlighter-rouge">repo_name</code> in the <code class="language-plaintext highlighter-rouge">bazel_dep</code> rule.
The repository name <code class="language-plaintext highlighter-rouge">com_google_protobuf</code> is <em>hard-coded</em> within the Bazel source code for the location
to discover the protoc compiler.</p>

<blockquote>
  <p>You’ll have to trust me that the resolution to the compiler for the language toolchains
such as <em>java_proto_library</em> is the same as well; just way more obfuscated.</p>
</blockquote>

<p>The rabbit hole only goes deeper if you consider <a href="https://grpc.io/">gRPC</a>, other languages and then having to manage
various runtimes (compatibility matrix) for your language across your codebases if they leave source of truth.</p>

<p>I feel like we discovered a lot but didn’t really learn or accomplish anything. 😩</p>

<h3 id="brighter-future">Brighter Future?</h3>

<p>Lots of interesting work is being done by the <a href="https://bazel-contrib.github.io/SIG-rules-authors/proto-grpc.html">rule-authors SIG</a> (Special Interest Group).</p>

<blockquote>
  <p>That doc has a great in-depth overview of the current <em>state of affairs</em>.</p>
</blockquote>

<p>The most notable changes on the horizon are migrating protocol buffers to Bazel’s toolchain mechanism.
This should make binding to <code class="language-plaintext highlighter-rouge">protoc</code> look like other toolchains in Bazel and no longer special case
<code class="language-plaintext highlighter-rouge">com_google_protobuf</code>.</p>

<blockquote>
  <p>What are toolchains? In my mind effectively the capability to late bind a label to a target.</p>
</blockquote>

<p>To me, a simple immediate improvement would be fixing the documentation around <em>rules_proto</em> and
having a more clear path on how to adopt Bazel given some constraint (i.e. Bazel &gt;= 7.0).</p>

<blockquote>
  <p>The <a href="https://blog.bazel.build/2017/02/27/protocol-buffers.html">latest blog post</a> from Bazel on protobuf
is from 2017!</p>
</blockquote>

<p>The work <a href="https://www.aspect.build/">Aspect Build</a> is doing to improve the protobuf ecosystem is great as well.
Their video series on <a href="https://www.youtube.com/watch?v=s0i_Ra_mG9U"><em>“Never Compile Protoc Again”</em></a> is excellent
and served as a great resource for my previous post on <a href="/2024/10/23/bazel-knowledge-mind-your-path.html">minding your PATH</a>.</p>
              </div>
            </article>
        <hr class="entry_sep">
          <article>
            <h2 class="entry_header">
              <a href="https://tech.j4m3s.eu/posts/git-filter-scripts/">
                Protect Your Sensitive Files in Git Repos: A Guide to Git Filters and age
                </a>
            </h2>
            <div class="entry_meta">
              <date>
                <span>10.11.2024 16:28</span>
                </date>
              </div>

            <div class="entry_summary">
                This blog post explores how to leverage Git clean/smudge filters alongside the age encryption tool to securely manage sensitive files in Git repositories. Git filters allow developers to preprocess files automatically, making them perfect for encrypting confidential data (e.g., API keys, configuration files) before committing to a repo and decrypting them upon checkout.
              </div>
            </article>
        <hr class="entry_sep">
          <article>
            <h2 class="entry_header">
              <a href="https://fzakaria.com/2024/11/08/jvm-boot-optimization-via-javaindex.html">
                JVM boot optimization via JavaIndex
                </a>
            </h2>
            <div class="entry_meta">
              <date>
                <span>08.11.2024 22:01</span>
                </date>
              </div>

            <div class="entry_content">
                <p><em>Ever heard of a JarIndex? I had been doing JVM development for 10+ years and I hadn’t. Read on to discover what it is and how it can speedup your compilation and boot time.</em> 🤓</p>

<p>After having worked on <a href="https://github.com/fzakaria/shrinkwrap">Shrinkwrap</a> and publishing our results in <a href="https://arxiv.org/abs/2211.05118">Mapping Out the HPC Dependency Chaos</a>, you start
to see the Linux environment as a bit of an oddball.</p>

<p><em>Everything in Linux is structured around O(n) or O(n^2) search and lookup</em>.</p>

<p>This feels now unsurprising given that everything in Linux searches across colon separate lists (i.e. <em>LD_LIBRARY_PATH</em>, <em>RUN_PATH</em>).
This idiom however is even more pervasive and has bled into all of our language.</p>

<p>The JVM for instance, must search for classes amongst a set of directories, files or JARs set on the <em>CLASS_PATH</em>.
<!--more--></p>

<p>Everytime the JVM needs to load a class file, it must perform a linear search along all entries in the <em>CLASS_PATH</em>.
Thanksfully, if the entries are directories or JARs, no subsequent search must be performed since the package name of a class dictates the directory structure
that must exist.</p>

<p><code class="language-plaintext highlighter-rouge">io.fzakaria.Example</code> -&gt; <code class="language-plaintext highlighter-rouge">io/fzakaria/Example.class</code></p>

<p>Nevertheless, the <em>CLASS_PATH</em> size can be large. 
At <em>$DAY_JOB$</em>, almost all of our services launch with +300 entries (JARs) on the ClassPath.</p>

<p>Large enterprise codebases may feature over a thousand ClassPath entries. 😮</p>

<p>A large ClassPath means that the JavaVirtualMachine (JVM) needs to search entry for the desired class.
This not only affects startup time for your application, <em>on every startup, repeatedly</em>, but also compilation as well via <code class="language-plaintext highlighter-rouge">javac</code>.</p>

<p>The authors of the JVM already knew about this problem, especially when the idea of Java Applets were dominant. Each JAR on the ClassPath
would have been fetched via HTTP and would cause unbearable slowdown for startup.</p>

<p>The JDK has support for a <em>JarIndex</em>.</p>

<p>A <em>JarIndex</em>, is a JAR which has a special file <code class="language-plaintext highlighter-rouge">INDEX.LIST</code> that effectively contains an index of all JARs on the ClassPath and the packages found within.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>JarIndex-Version: 1.0

libMain.jar
Main.class

lib/libA.jar
A.class

lib/libB.jar
B.class
</code></pre></div></div>

<p>Whenever a class must be searched rather than searching through the <em>CLASS_PATH</em>, the index file is used leading to constant-time lookup for classes.</p>

<p>This seemingly powerful primitive confusingly has been deprecated and ultimately removed in JDK22 (<a href="https://bugs.openjdk.org/browse/JDK-8302819">JDK-8302819</a>) 🤔 – citing challenges when having to support a broad ranges of topics such as Multi-Version JARs.</p>

<p>Unsuprisingly, I think this feature would be an easy fit into Bazel, Spack or Nix – as there are a lot more constraints on the type of JARs that need be supported.</p>

<p>I put together a small <a href="https://gist.github.com/fzakaria/4e98f65be96cf7f8b13081e75d7a2bf8">gist</a> on what this support might look like.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">_jar_index_impl</span><span class="p">(</span><span class="n">ctx</span><span class="p">):</span>
    <span class="n">java_info</span> <span class="o">=</span> <span class="n">ctx</span><span class="p">.</span><span class="n">attr</span><span class="p">.</span><span class="n">src</span><span class="p">[</span><span class="n">JavaInfo</span><span class="p">]</span>
    <span class="n">java_runtime</span> <span class="o">=</span> <span class="n">ctx</span><span class="p">.</span><span class="n">attr</span><span class="p">.</span><span class="n">_java_runtime</span><span class="p">[</span><span class="n">java_common</span><span class="p">.</span><span class="n">JavaRuntimeInfo</span><span class="p">]</span>
    <span class="n">java_home</span> <span class="o">=</span> <span class="n">java_runtime</span><span class="p">.</span><span class="n">java_home</span>
    <span class="n">jar_bin</span> <span class="o">=</span> <span class="s">"%s/bin/jar"</span> <span class="o">%</span> <span class="n">java_home</span>

    <span class="n">runtime_jars</span> <span class="o">=</span> <span class="s">" "</span>
    <span class="k">for</span> <span class="n">jar</span> <span class="ow">in</span> <span class="n">java_info</span><span class="p">.</span><span class="n">transitive_runtime_jars</span><span class="p">.</span><span class="n">to_list</span><span class="p">():</span>
        <span class="n">runtime_jars</span> <span class="o">+=</span> <span class="n">jar</span><span class="p">.</span><span class="n">path</span> <span class="o">+</span> <span class="s">" "</span>

    <span class="n">cmds</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s">"%s -i %s %s"</span> <span class="o">%</span> <span class="p">(</span><span class="n">jar_bin</span><span class="p">,</span> <span class="n">java_info</span><span class="p">.</span><span class="n">java_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">class_jar</span><span class="p">.</span><span class="n">path</span><span class="p">,</span> <span class="n">runtime_jars</span><span class="p">),</span>
        <span class="s">"cp %s %s"</span> <span class="o">%</span> <span class="p">(</span><span class="n">java_info</span><span class="p">.</span><span class="n">java_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">class_jar</span><span class="p">.</span><span class="n">path</span><span class="p">,</span> <span class="n">ctx</span><span class="p">.</span><span class="n">outputs</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">path</span><span class="p">),</span>
    <span class="p">]</span>

    <span class="n">ctx</span><span class="p">.</span><span class="n">actions</span><span class="p">.</span><span class="n">run_shell</span><span class="p">(</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span> <span class="n">java_info</span><span class="p">.</span><span class="n">java_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">class_jar</span><span class="p">]</span> <span class="o">+</span> <span class="n">java_info</span><span class="p">.</span><span class="n">transitive_runtime_jars</span><span class="p">.</span><span class="n">to_list</span><span class="p">(),</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">ctx</span><span class="p">.</span><span class="n">outputs</span><span class="p">.</span><span class="n">index</span><span class="p">],</span>
        <span class="n">tools</span> <span class="o">=</span> <span class="n">java_runtime</span><span class="p">.</span><span class="n">files</span><span class="p">,</span>
        <span class="n">command</span> <span class="o">=</span> <span class="s">";</span><span class="se">\n</span><span class="s">"</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">cmds</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="p">[</span>
        <span class="n">DefaultInfo</span><span class="p">(</span><span class="n">files</span> <span class="o">=</span> <span class="n">depset</span><span class="p">([</span><span class="n">ctx</span><span class="p">.</span><span class="n">outputs</span><span class="p">.</span><span class="n">index</span><span class="p">])),</span>
    <span class="p">]</span>

<span class="n">jar_index</span> <span class="o">=</span> <span class="n">rule</span><span class="p">(</span>
    <span class="n">implementation</span> <span class="o">=</span> <span class="n">_jar_index_impl</span><span class="p">,</span>
    <span class="n">attrs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">"src"</span><span class="p">:</span> <span class="n">attr</span><span class="p">.</span><span class="n">label</span><span class="p">(</span>
            <span class="n">mandatory</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
            <span class="n">providers</span> <span class="o">=</span> <span class="p">[</span><span class="n">JavaInfo</span><span class="p">],</span>
        <span class="p">),</span>
        <span class="s">"_java_runtime"</span><span class="p">:</span> <span class="n">attr</span><span class="p">.</span><span class="n">label</span><span class="p">(</span>
            <span class="n">default</span> <span class="o">=</span> <span class="s">"@bazel_tools//tools/jdk:current_java_runtime"</span><span class="p">,</span>
            <span class="n">providers</span> <span class="o">=</span> <span class="p">[</span><span class="n">java_common</span><span class="p">.</span><span class="n">JavaRuntimeInfo</span><span class="p">],</span>
        <span class="p">),</span>
    <span class="p">},</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="p">{</span><span class="s">"index"</span><span class="p">:</span> <span class="s">"%{name}_index.jar"</span><span class="p">},</span>
<span class="p">)</span>
</code></pre></div></div>

<p>Further improvements can be made, to give this index-like support to the Java compiler itself and not only for <code class="language-plaintext highlighter-rouge">java_binary</code> targets.</p>

<p>We’ve gone out of our way on these systems to define our inputs, enforce contraints and model our dependencies. Not taking advantage of
this stability and regressing to the default search often found in our tooling is leaving easy performance improvements on the floor.</p>
              </div>
            </article>
        <hr class="entry_sep">
          <article>
            <h2 class="entry_header">
              <a href="https://leahneukirchen.org/blog/archive/2024/11/problem-solving-with-answer-set-programming.html">
                Problem Solving with Answer Set Programming
                </a>
            </h2>
            <div class="entry_meta">
              <date>
                <span>06.11.2024 21:47</span>
                </date>
              &mdash; <span class="entry_author">Leah Neukirchen</span>
              </div>

            <div class="entry_content">
                <p>A few months ago I found an article on how to
<a href="https://alt-romes.github.io/posts/2024-08-14-planning-a-workout-week-with-100-lines-of-haskell.html">organize your training plan using logic programming</a>,
which used Haskell to implement a logic language.</p>
<p>At first, I thought this is a good problem to solve in Prolog, but
there’s a difficulty: Prolog makes it quite hard to specify models
that have multiple possible outcomes (yes, you can work with backtracking, but
it gets tricky when you start to combine multiple predicates or fiddle
around with <code>bagof</code>).</p>
<p>An alternative to classic Prolog is the concept of Answer Set
Programming, based on the <a href="https://www.cs.utexas.edu/~ai-lab/?gel88=">Stable Model Semantics by Gelfond and
Lifschitz</a> (1988).  Here,
the idea is that the logical formulas specify models, and the goal of
Answer Set Programming is to compute the Answer Sets, i.e. a set of
models fulfilling the formulas.</p>
<p>I can’t do a full introduction to Answer Set Programming here,
but I can recommend the overview article <a href="https://dl.acm.org/doi/10.1145/2043174.2043195">Answer set programming at a glance</a> by Brewka et. al.,
as well as
the short article <a href="https://www.cs.utexas.edu/~vl/papers/wiasp.pdf">What Is Answer Set Programming?</a>
and the book <a href="https://link.springer.com/book/10.1007/978-3-030-24658-7">Answer Set Programming</a> by Lifschitz.</p>
<h4>So what is a stable model?</h4>
<p>Essentially, we can think of a stable model as a maximal set of atoms
that are true (derivable from the rules) without being in conflict to
other propositions.  If we don’t use negation, that pretty boring</p>
<p>However, consider this logic program:</p>
<pre><code>q :- not p.
p :- not q.
</code></pre>
<p>Contrary to what you may expect, it has two models: {p} and {q}.
This is because ASP uses default negation, which means “not A” is
assumed to hold unless A is derived.
Both cannot be true at the same time, but likewise the empty set
is not a model because it can be extended to {p} or {q}.</p>
<p>The program <code>p :- not not p.</code> has two models, {} and {p}.</p>
<p>Let’s do a small problem first so we get a feel for the tooling.  I
chose to use <a href="https://potassco.org/clingo/">clingo</a>, which is the most
advanced open source implementation of Answer Set Programming.</p>
<p>If your distribution doesn’t include it, you can run it from Nix:</p>
<pre><code>nix shell nixpkgs#clingo
</code></pre>
<p>Let’s model a directed graph with four nodes:</p>
<pre><code>edge(a,b).
edge(a,c).
edge(b,d).
edge(c,d).
</code></pre>
<p>Our problem is to find paths from <code>a</code> to <code>d</code>.  We can define a
relation <code>step</code>, which either means “we can step from X to <code>d</code>”
or “we can step from X to Y when there’s an edge from X to Y and
another step from Y”:</p>
<pre><code>0 { step(X,E) } 1 :- edge(X,E), E = d.
0 { step(X,Y) } 1 :- edge(X,Y), step(Y,_).
</code></pre>
<p>The <code>0 { ... } 1</code> decoration means that each step can be taken at most once.</p>
<p>Finally, we need to specify our goal, which in tradition of logic
programming, is written as a negation:</p>
<pre><code>:- not step(a,_).
#show step/2.
</code></pre>
<p>This means “it is not the case that there’s no step starting from <code>a</code>”.</p>
<p>The <code>#show</code> instructions limits clingo to only output the binary
<code>step</code> relation.  Let’s run it:</p>
<pre><code>% gringo graph.pl | clasp    
clasp version 3.3.10
Reading from stdin
Solving...
Answer: 1
step(b,d) step(a,b)
SATISFIABLE

Models       : 1+
Calls        : 1
Time         : 0.001s (Solving: 0.00s 1st Model: 0.00s Unsat: 0.00s)
CPU Time     : 0.000s
</code></pre>
<p>Clingo has found a solution.  We can go from <code>a</code> to <code>b</code> and from <code>b</code> to <code>d</code>.</p>
<p>We can also ask for all solutions, by passing <code>-n0</code>:</p>
<pre><code>% gringo graph.pl | clasp -n0
clasp version 3.3.10
Reading from stdin
Solving...
Answer: 1
step(b,d) step(a,b)
Answer: 2
step(c,d) step(b,d) step(a,b)
Answer: 3
step(c,d) step(a,c)
Answer: 4
step(c,d) step(b,d) step(a,c)
Answer: 5
step(c,d) step(b,d) step(a,b) step(a,c)
SATISFIABLE

Models       : 5
Calls        : 1
Time         : 0.000s (Solving: 0.00s 1st Model: 0.00s Unsat: 0.00s)
CPU Time     : 0.000s
</code></pre>
<p>Here we see there are five possible models of this system (but every
model except the first and the third has superflous steps).</p>
<p>To see why the <code>0 { ... } 1</code> matters, here’s what happens without it:</p>
<pre><code>Answer: 1
step(b,d) step(c,d) step(a,b) step(a,c)
SATISFIABLE
</code></pre>
<p>Now there is only one model, but it contains all paths.
Cardinality bounds are implemented using negation internally.</p>
<h4>Planning Weekly Workouts in 30 lines of ASP</h4>
<p>Back to the original task:
<a href="https://alt-romes.github.io/posts/2024-08-14-planning-a-workout-week-with-100-lines-of-haskell.html">Planning Weekly Workouts in 100 lines of Haskell</a>.</p>
<p>The goal is to create a weekly plan of training exercises according to
some specific rules.</p>
<p>First, we need some definitions related to weekdays:</p>
<pre><code>weekday(1..7).

n_weekday(D, DD)  :- weekday(D), weekday(DD), (D+1) \ 7 == DD \ 7.
nn_weekday(D, DD) :- weekday(D), weekday(DD), (D+2) \ 7 == DD \ 7.

two_weekday(D, DD) :- n_weekday(D, DD).
two_weekday(D, DD) :- nn_weekday(D, DD).
two_weekday(D, DD) :- two_weekday(DD, D).
</code></pre>
<p>This is a bit more complicated because we later need “day after”
and “within two days”.  (<code>\</code> means modulo.)</p>
<p>Now, let’s define workout and running exercises:</p>
<pre><code>workout(push; pull; leg; none).
running(long; short; none).
</code></pre>
<p>To the plan: each weekday has one workout and one running exercise:</p>
<pre><code>{ plan(D,W,R) : workout(W), running(R) } = 1 :- weekday(D).
</code></pre>
<p>We then add the constraints:</p>
<pre><code>% No running on leg day
plan(D, leg, none) :- plan(D, leg, _).

% Short intervals run is after an outdoor pull/push workout
:- plan(_, none, short).

% Workout on Monday outdoors always, not legs
:- plan(1, none, _).
:- plan(1, leg, _).

% Pull day during the week?
:- plan(6..7, pull, _).

% One long run, one short run
{ plan(D,W,long) : weekday(D), workout(W) } = 1.
{ plan(D,W,short) : weekday(D), workout(W) } = 1.

% Two push, two pull, two leg
:- not { plan(D,push,R) } = 2.
:- not { plan(D,pull,R) } = 2.
:- not { plan(D,leg,R) } = 2.

% Long run on weekend
{ plan(6..7,W,long) : workout(W) } = 1.

% Run spaced out at least 2 days
:- plan(D,_,short), plan(DD,_,long), two_weekday(D, DD).

% Space out workouts at least 2 days
:- plan(D,W,_), plan(DD,W,_), W != none, two_weekday(D, DD).

% No leg day before short run
% No leg day before a long run
{ plan(D,W,R) : running(R), R != none, workout(W), plan(DD,leg,_), n_weekday(D, DD) } = 1.

#show plan/3.
</code></pre>
<p>clingo generates the same three plans as the Haskell program:</p>
<pre><code>Solving...
Answer: 1
plan(5,leg,none) plan(2,leg,none) plan(1,pull,none) plan(3,push,none) plan(4,pull,short) plan(6,push,none) plan(7,none,long)
Answer: 2
plan(5,leg,none) plan(2,leg,none) plan(1,pull,none) plan(3,push,none) plan(4,pull,short) plan(6,none,none) plan(7,push,long)
Answer: 3
plan(7,leg,none) plan(4,leg,none) plan(1,pull,none) plan(2,push,short) plan(3,none,none) plan(5,pull,none) plan(6,push,long)
SATISFIABLE
</code></pre>
<h4>Answer Set Programming against heteronormativity</h4>
<p>The next problem I solved using ASP was a silly exercise from
a statistics book
(Lehn, Wegmann, Rettig: Aufgabensammlung zur Einführung in die Statistik),
translation mine:</p>
<blockquote>
<p>Exercise 11c) Ten French married couples bid goodbye to each other:
the men with the men by shaking hands, the women with the women by
kisses on both cheeks, and women with the men likewise by kisses on
both cheeks.  How many kisses and how many handshakes take place?</p>
</blockquote>
<p>The implicit assumption of the exercise is that all married couples
consist of a man and a woman, but it’s more fun to solve it in a
generic way.  So let’s do that using ASP.</p>
<p>First, we model the people and their fixed binary gender (more assumptions,
but else the exercise is truly underspecified):</p>
<pre><code>person(0..19).
gender(man; woman).
{ gender(P, G) : gender(G) } = 1 :- person(P).
</code></pre>
<p>I decided to model a couple using an even and odd numbered person:</p>
<pre><code>couple(A, B) :- person(A), person(B), A != B, A/2 == B/2.
</code></pre>
<p>Next, we model the handshakes.  Two people shake hands if they are not
part of the same couple, and both are men:</p>
<pre><code>handshake(A, B) :- person(A), person(B), A &lt; B, not couple(A, B), gender(A, man), gender(B, man).
</code></pre>
<p>The <code>A &lt; B</code> ensures we only count one handshake between two men,
as handshaking is a symmetric act.</p>
<p>We also count the handshakes:</p>
<pre><code>handshakes(N) :- N = #count { handshakes(A, B) : handshake(A, B) }.
</code></pre>
<p>Likewise, two kisses happen between two persons not in the same couple
where one is a woman.  Note that kisses are asymmetric since they go
from mouth to cheek (this cost me an hour of debugging…):</p>
<pre><code>kiss(A, B) :- person(A), person(B), not A == B, not couple(A, B), gender(A, woman).
kiss(A, B) :- person(A), person(B), not A == B, not couple(A, B), gender(B, woman).
kisses(N) :- H = #count { kisses(A, B) : kiss(A, B) }, N = H * 2.
</code></pre>
<p>Finally, we also count men and women for reporting purposes:</p>
<pre><code>men(N) :- N = #count { g(P) : gender(P, man) }.
women(N) :- N = #count { g(P) : gender(P, woman) }.

#show handshakes/1.
#show kisses/1.
#show men/1.
#show women/1.
</code></pre>
<p>Thanks to clingo’s parallelization support, we can compute all
possible 2<sup>20</sup> solutions very quickly:</p>
<pre><code>Solving...
Answer: 1
women(0) men(20) kisses(0) handshakes(180)
Answer: 2
women(1) men(19) kisses(72) handshakes(162)
Answer: 3
women(1) men(19) kisses(72) handshakes(162)
...
Answer: 1048576
women(12) men(8) kisses(616) handshakes(26)
SATISFIABLE

Models       : 1048576
Calls        : 1
Time         : 51.163s (Solving: 51.00s 1st Model: 0.10s Unsat: 0.01s)
CPU Time     : 463.811s
Threads      : 16       (Winner: 0)
</code></pre>
<p>We can also specialize the model to have only hetero couples:</p>
<pre><code>:- Z = 0..9, not gender(2*Z, man).
:- Z = 0..9, not gender(2*Z+1, woman).
</code></pre>
<p>Then we get the unique solution:</p>
<pre><code>Solving...
Answer: 1
women(10) men(10) kisses(540) handshakes(45)
SATISFIABLE
</code></pre>
<p>I hope this post could interest you in how Answer Set Programming can be used.
Some more interesting programs can be found on
<a href="http://www.hakank.org/constraint_programming_blog/answer_set_programming/">Hakan Kjellerstrand’s blog</a>.</p>
              </div>
            </article>
        <hr class="entry_sep">
          <article>
            <h2 class="entry_header">
              <a href="https://fzakaria.com/2024/10/29/bazel-knowledge-what-s-an-interface-jar.html">
                Bazel Knowledge: What’s an Interface JAR?
                </a>
            </h2>
            <div class="entry_meta">
              <date>
                <span>30.10.2024 02:34</span>
                </date>
              </div>

            <div class="entry_content">
                <p>I spent the day working through an upgrade of our codebase at <em>$DAYJOB$</em> to Java21 and hit Bazel <a href="https://github.com/bazelbuild/bazel/issues/24138">issue#24138</a> as a result of an incorrectly produced <code class="language-plaintext highlighter-rouge">hjar</code>.</p>

<p>🤨
<em>WTF is an <code class="language-plaintext highlighter-rouge">hjar</code> ?</em></p>

<p>☝️ <em>It is the newer version of <code class="language-plaintext highlighter-rouge">ijar</code> !</em></p>

<p>😠
<em>WTF is an <code class="language-plaintext highlighter-rouge">ijar</code> ?</em></p>

<p>Let’s discover what an <code class="language-plaintext highlighter-rouge">ijar</code> (Interface JAR) is and how it’s the <em>magic sauce</em> that makes Bazel so fast for Java.</p>

<!--more-->

<p>Let’s consider a simple Makefile</p>

<div class="language-make highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nl">program</span><span class="o">:</span> <span class="nf">main.o utils.o</span>
	<span class="nv">$(CC)</span> <span class="nt">-o</span> program main.o utils.o

<span class="nl">main.o</span><span class="o">:</span> <span class="nf">main.c utils.h</span>
	<span class="nv">$(CC)</span> <span class="nt">-c</span> main.c

<span class="nl">utils.o</span><span class="o">:</span> <span class="nf">utils.c utils.h</span>
	<span class="nv">$(CC)</span> <span class="nt">-c</span> utils.c
</code></pre></div></div>

<p>We’ve been taught to make use of <em>header files</em>, especially in C/C++ so that we can avoid recompilation as a form of <em>early cutoff optimization</em>.</p>

<p>☝️ If we change <code class="language-plaintext highlighter-rouge">utils.c</code> solely, we do not have to recompile <code class="language-plaintext highlighter-rouge">main.o</code>.</p>

<p>We can visualize this Makefile in the following graph.</p>

<p><img src="/assets/images/makefile_as_graph.svg" alt="Makefile as a graph" /></p>

<p>Ok, great! What does this have to do with Java &amp; Bazel ?</p>

<p>Well, let’s remember back to my previous post on <a href="/2024/09/26/bazel-knowledge-reproducible-outputs.html">reproducible outputs</a>.</p>

<p>Bazel constructs a similar graph to determine when to do <em>early cutoff optimization</em> through the “Action Key”. Bazel computes a hash for each action, that takes dependencies for instance, and if the hash hasn’t changed it can memoize the work.</p>

<p><img src="/assets/images/action_graph_bazel.png" alt="Bazel Action Graph" /></p>

<p>In Java-world, dependencies are expressed as JARs.</p>

<p>Wouldn’t private-only changes to a dependency (i.e. renaming a private variable) cause the Action Key HASH to change (since it produced a different JAR) ?</p>

<p>🤓 YES! That is why we need an <code class="language-plaintext highlighter-rouge">ijar</code> !</p>

<p><code class="language-plaintext highlighter-rouge">ijar</code> is a tool found within the Bazel repository <a href="https://github.com/bazelbuild/bazel/blob/master/third_party/ijar/README.txt">bazel/third_party/ijar</a>.</p>

<p>You can build and run it fairly simple with Bazel</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>bazel run //third_party/ijar
Usage: ijar <span class="o">[</span><span class="nt">-v</span><span class="o">]</span> <span class="o">[</span><span class="nt">--</span><span class="o">[</span>no]strip_jar] <span class="o">[</span><span class="nt">--target</span> label label] <span class="o">[</span><span class="nt">--injecting_rule_kind</span> kind] x.jar <span class="o">[</span>x_interface.j
ar&gt;]
Creates an interface jar from the specified jar file.
</code></pre></div></div>

<p>It’s purpose is straightforward. The tool strips all non-public information from the JAR. For example, it throws away:</p>
<ul>
  <li>Files whose name does not end in “.class”.</li>
  <li>All executable method code.</li>
  <li>All private methods and fields.</li>
  <li>All constants and attributes except the minimal set necessary to describe the class interface.</li>
  <li>All debugging information
(LineNumberTable, SourceFile, LocalVariableTables attributes).</li>
</ul>

<p>The end result is something in spirit to a C/C++ header file.</p>

<p>Let’s see it in practice. 🕵️</p>

<p>Let’s now create an incredibly simple JAR. It will have a single class file within it.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">class</span> <span class="nc">Banana</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">peel</span><span class="o">()</span> <span class="o">{</span>
        <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"Peeling the banana..."</span><span class="o">);</span>
        <span class="n">squish</span><span class="o">();</span>
    <span class="o">}</span>
    <span class="kd">private</span> <span class="kt">void</span> <span class="nf">squish</span><span class="o">()</span> <span class="o">{</span>
        <span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"Squish! The banana got squashed."</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p>We compile it like usual.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>javac Banana.java
<span class="nv">$ </span>jar cf banana.jar Banana.class
</code></pre></div></div>

<p>When we run <code class="language-plaintext highlighter-rouge">ijar</code> on it we get the hash <em>e18e0ae82bdc4deb04f04aa</em></p>

<p>⚠️ I shortened the hashes to make them more legible.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>bazel-bin/third_party/ijar/ijar banana.jar

<span class="nv">$ </span><span class="nb">sha256sum </span>banana.jar
f813749013ea6aba2e00876  banana.jar

<span class="nv">$ </span><span class="nb">sha256sum </span>banana-interface.jar
e18e0ae82bdc4deb04f04aa  banana-interface.jar
</code></pre></div></div>

<p>Let’s now change the internals of the <em>Banana</em> class; let’s rename the method <code class="language-plaintext highlighter-rouge">squish()</code> -&gt; <code class="language-plaintext highlighter-rouge">squash()</code>.</p>

<p>Let’s recompute the new sha256.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sha256sum </span>banana.jar
9278282827ddb55c68eb370 banana.jar

<span class="nv">$ </span><span class="nb">sha256sum </span>banana-interface.jar
e18e0ae82bdc4deb04f04aa  banana-interface.jar
</code></pre></div></div>

<p>🤯 Although the hash of <em>banana.jar</em> had changed, we still get <em>e18e0ae82bdc4deb04f04aa</em> for the ijar.</p>

<p>We now the equivalent of a header file for Java code.  🙌</p>

<p>Bazel will use the <code class="language-plaintext highlighter-rouge">ijar</code> when computing the Action Key hash in lieu of the JAR for the dependencies you may depend on; thus avoiding costly rebuilds when only private information changes within your dependency.</p>

<p>This is the amazing lesser known tool that makes Bazel super-powered 🦸 for JVM languages.</p>
              </div>
            </article>
        <hr class="entry_sep">
          <article>
            <h2 class="entry_header">
              <a href="https://fzakaria.com/2024/10/23/bazel-knowledge-mind-your-path.html">
                Bazel Knowledge: mind your PATH
                </a>
            </h2>
            <div class="entry_meta">
              <date>
                <span>23.10.2024 22:37</span>
                </date>
              </div>

            <div class="entry_content">
                <p>Have you encountered the following?</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> bazel build
INFO: Invocation ID: f16c3f83-0150-494e-bd34-1a9cfb6a2e67
WARNING: Build option <span class="nt">--incompatible_strict_action_env</span> has changed, discarding analysis cache <span class="o">(</span>this can be expensive, see https://bazel.build/advanced/performance/iteration-speed<span class="o">)</span><span class="nb">.</span>
INFO: Analyzed target @@com_google_protobuf//:protoc <span class="o">(</span>113 packages loaded, 1377 targets configured<span class="o">)</span><span class="nb">.</span>
<span class="o">[</span>483 / 845] 13 actions, 12 running
    Compiling src/google/protobuf/compiler/importer.cc<span class="p">;</span> 3s disk-cache, darwin-sandbox
    Compiling src/google/protobuf/compiler/java/names.cc<span class="p">;</span> 1s disk-cache, darwin-sandbox
    Compiling src/google/protobuf/compiler/java/name_resolver.cc<span class="p">;</span> 1s disk-cache, darwin-sandbox
    Compiling src/google/protobuf/compiler/java/helpers.cc<span class="p">;</span> 1s disk-cache, darwin-sandbox
    Compiling src/google/protobuf/compiler/objectivec/enum.cc<span class="p">;</span> 1s disk-cache, darwin-sandbox
    Compiling absl/strings/cord.cc<span class="p">;</span> 1s disk-cache, darwin-sandbox
    Compiling src/google/protobuf/compiler/objectivec/names.cc<span class="p">;</span> 0s disk-cache, darwin-sandbox
    Compiling absl/time/internal/cctz/src/time_zone_lookup.cc<span class="p">;</span> 0s disk-cache, darwin-sandbox ...
</code></pre></div></div>

<p>I finally had it with Bazel <strong>recompiling protoc</strong> 😤</p>

<p>The working title for this post: <em>Why the #$@! does protoc keep recompiling!</em> 🤬</p>

<blockquote>
  <p>If you are not interested in the story and just want to avoid recompiling <em>protoc</em>, try putting <code class="language-plaintext highlighter-rouge">build --incompatible_strict_action_env</code> in your <em>.bazelrc</em>.</p>

  <p>Checkout Aspect’s <a href="https://docs.aspect.build/guides/bazelrc/">bazelrc guide</a> for other good tidbits.</p>
</blockquote>

<!--more-->

<p>Admittedly, I’ve been using Bazel a while and I wasn’t sure why I kept having to rebuild <em>protoc</em> despite nothing seemingly changing on my system.</p>

<p>Worse, my coworkers who I’ve been working hard to champion Bazel were starting to notice.</p>

<p><em>“You explained that Bazel is supposed to be hermetic and have great caching. Why am I recompiling protoc?”</em></p>

<p>This seems to be a bit of an issue within the Bazel community so much so, that one recommended approach is just <em>use precompiled binaries</em> via <a href="https://github.com/aspect-build/toolchains_protoc">aspect-build/toolchains_protoc</a>. 🤦</p>

<blockquote>
  <p><em>Aside</em>: Using prebuilt binaries not only hinders my own personal adoption of Bazel on <a href="https://nixos.org">NixOS</a> but devalues the value proposition of Bazel itself.</p>
</blockquote>

<p>Turns out there is a long-standing <strong>5 year old</strong> issue <a href="https://github.com/bazelbuild/bazel/issues/7095">issues#7095</a> that provided some clues; specifically changing <code class="language-plaintext highlighter-rouge">PATH</code> is busting the action key.</p>

<p>I want to validate this assumption, by following the guide on <a href="https://bazel.build/remote/cache-remote">how to debug remote cache hits</a>.</p>

<p>I ran Bazel twice, once with a different <code class="language-plaintext highlighter-rouge">PATH</code> and stored the compact execution log.
I then convert it to textual form and diff them.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># build protoc normally</span>
<span class="o">&gt;</span> bazel build @com_google_protobuf//:protoc <span class="se">\</span>
    <span class="nt">--execution_log_compact_file</span><span class="o">=</span>/tmp/exec1.log

<span class="c"># muck up the PATH</span>
<span class="o">&gt;</span> <span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:/bin4/ bazel build @com_google_protobuf//:protoc <span class="se">\</span>
    <span class="nt">--execution_log_compact_file</span><span class="o">=</span>/tmp/exec2.log

<span class="o">&gt;</span> bazel-bin/src/tools/execlog/parser <span class="se">\</span>
  <span class="nt">--log_path</span><span class="o">=</span>/tmp/exec1.log <span class="se">\</span>
  <span class="nt">--log_path</span><span class="o">=</span>/tmp/exec2.log <span class="se">\</span>
  <span class="nt">--output_path</span><span class="o">=</span>/tmp/exec1.log.txt <span class="se">\</span>
  <span class="nt">--output_path</span><span class="o">=</span>/tmp/exec2.log.txt

<span class="o">&gt;</span> diff /tmp/exec1.log.txt /tmp/exec2.log.txt | <span class="nb">head</span> <span class="nt">-n</span> 30
<span class="c"># omitted for brevity</span>
</code></pre></div></div>

<p>Sure enough; there is an <code class="language-plaintext highlighter-rouge">action_env</code> with the <code class="language-plaintext highlighter-rouge">PATH</code> variable and it’s different, causing the action digest to change.</p>

<p>But, why! 🤔</p>

<p>Some of the actions used in the C++ toolchain use the shell’s default environment.
For instance, Bazel doesn’t include a C++ toolchain by default so it has to find a C++ compiler by searching
on the <code class="language-plaintext highlighter-rouge">PATH</code> itself.</p>

<p>We can test this (thanks to <a href="https://github.com/keith">keith</a> for this) with a small demo.
We can see what envs are in actions by default passing <code class="language-plaintext highlighter-rouge">-s</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">_impl</span><span class="p">(</span><span class="n">ctx</span><span class="p">):</span>
    <span class="nb">file</span> <span class="o">=</span> <span class="n">ctx</span><span class="p">.</span><span class="n">actions</span><span class="p">.</span><span class="n">declare_file</span><span class="p">(</span><span class="n">ctx</span><span class="p">.</span><span class="n">label</span><span class="p">.</span><span class="n">name</span><span class="p">)</span>
    <span class="n">ctx</span><span class="p">.</span><span class="n">actions</span><span class="p">.</span><span class="n">run_shell</span><span class="p">(</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">file</span><span class="p">],</span>
        <span class="n">command</span> <span class="o">=</span> <span class="s">"touch {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">file</span><span class="p">.</span><span class="n">path</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">DefaultInfo</span><span class="p">(</span><span class="n">files</span> <span class="o">=</span> <span class="n">depset</span><span class="p">([</span><span class="nb">file</span><span class="p">]))</span>

<span class="n">foo</span> <span class="o">=</span> <span class="n">rule</span><span class="p">(</span>
    <span class="n">implementation</span> <span class="o">=</span> <span class="n">_impl</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div></div>

<p>Will produce:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SUBCOMMAND: <span class="c"># //:bar [action 'Action bar', configuration: 815f76489fb61a0245ff1941974c20af0ca4e7f91caa00c80538d4493d650289, execution platform: @@platforms//host:host, mnemonic: Action]</span>
<span class="o">(</span><span class="nb">cd</span> /home/ubuntu/.cache/bazel/_bazel_ubuntu/1275a810ad76d4d1cc60319d4aaf0d39/execroot/_main <span class="o">&amp;&amp;</span> <span class="se">\</span>
  <span class="nb">exec env</span> - <span class="se">\</span>
  /bin/bash <span class="nt">-c</span> <span class="s1">'touch bazel-out/aarch64-fastbuild/bin/bar'</span><span class="o">)</span>
</code></pre></div></div>

<p>If we change the <code class="language-plaintext highlighter-rouge">run_shell</code> action to use <code class="language-plaintext highlighter-rouge">use_default_shell_env=True</code> we then get.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SUBCOMMAND: <span class="c"># //:bar [action 'Action bar', configuration: 815f76489fb61a0245ff1941974c20af0ca4e7f91caa00c80538d4493d650289, execution platform: @@platforms//host:host, mnemonic: Action]</span>
<span class="o">(</span><span class="nb">cd</span> /home/ubuntu/.cache/bazel/_bazel_ubuntu/1275a810ad76d4d1cc60319d4aaf0d39/execroot/_main <span class="o">&amp;&amp;</span> <span class="se">\</span>
  <span class="nb">exec env</span> - <span class="se">\</span>
    <span class="nv">PATH</span><span class="o">=</span>&lt;OMITTED FOR BREVITY&gt; <span class="se">\</span>
  /bin/bash <span class="nt">-c</span> <span class="s1">'touch bazel-out/aarch64-fastbuild/bin/bar'</span><span class="o">)</span>
</code></pre></div></div>

<p>Okay, so how do we solve this?</p>

<p>There are two ways to solve this.</p>

<p>First, you can try <code class="language-plaintext highlighter-rouge">--incompatible_strict_action_env</code> in your <em>.bazerc</em> file.
If this flag is set, Bazel will force set <code class="language-plaintext highlighter-rouge">PATH</code> to be a static value. If your C++ compiler is either a hermetic toolchain or found in the default lists set; you are good to go!</p>

<p>If you tried the first option but your build is failing, you’ll have to manually force set the <code class="language-plaintext highlighter-rouge">PATH</code> via the <code class="language-plaintext highlighter-rouge">action_env</code> flag such as <code class="language-plaintext highlighter-rouge">--action_env=PATH=/usr/bin:/something/custom</code></p>

<p>Hopefully these settings get you from recompiling <em>protoc</em> and reach Bazel nirvana.</p>

<p>I highly recommend <a href="https://docs.aspect.build/guides/bazelrc/">Aspect’s bazelrc guide</a> for other no-nonsense settings that should likely just be the default 🙄</p>
              </div>
            </article>
        <hr class="entry_sep">
          <article>
            <h2 class="entry_header">
              <a href="https://fzakaria.com/2024/10/13/bazel-knowledge-aspects-to-generate-java-classpath.html">
                Bazel Knowledge: Aspects to generate Java CLASSPATH
                </a>
            </h2>
            <div class="entry_meta">
              <date>
                <span>13.10.2024 18:10</span>
                </date>
              </div>

            <div class="entry_content">
                <p>One of the more advanced features of <a href="https://bazel.build">Bazel</a> is the concept of <a href="https://bazel.build/extending/aspects">aspect</a>.</p>

<p>For a very brief primer on why you may want an aspect is that Bazel let’s you audit and analyze the BUILD graph without performing any actual builds. It does this by constructing a “shadow graph” that your aspect can perform analysis on. This can be useful for a variety things such as IDE integration.</p>

<p>I wanted to ask a very simple question to make integration with Visual Studio Code straightforward:</p>

<p><em>“What’s the CLASSPATH I need for a particular target so that I don’t get red squigglies?”</em></p>

<!--more-->

<p>Sometimes simple questions involve some of the more advanced features of Bazel.
I wanted to generate a file that I can feed into any IDE, such as Visual Studio Code, and get semi-decent language integration.</p>

<p>My end goal:</p>
<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">&gt;</span><span class="w"> </span>bazel build //:generate_classpath
<span class="go">
</span><span class="gp">&gt;</span><span class="w"> </span><span class="nb">cat </span>bazel-bin/classpath.txt
<span class="go">bazel-out/k8-fastbuild/bin/java/lib/liblib.jar
bazel-out/k8-fastbuild/bin/java/lib2/liblib2.jar
</span></code></pre></div></div>

<p>First thing we want to do is generate an aspect that will collect recursively all the compile time Jars.</p>

<p>We define our aspect which requires the sole <code class="language-plaintext highlighter-rouge">deps</code> attribute to be propagated.
We then make sure we recursively merge all the results of the prior aspect invocations into the final
<code class="language-plaintext highlighter-rouge">ClassPathInfo</code> provider object.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ClassPathInfo</span> <span class="o">=</span> <span class="n">provider</span><span class="p">(</span>
    <span class="s">"Provider for classpath information"</span><span class="p">,</span>
    <span class="n">fields</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">'compile_jars'</span> <span class="p">:</span> <span class="s">'depset of compile jars'</span>
    <span class="p">}</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">_classpath_aspect_impl</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
    <span class="c1"># Make sure the rule has a deps attribute.
</span>    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">ctx</span><span class="p">.</span><span class="n">rule</span><span class="p">.</span><span class="n">attr</span><span class="p">,</span> <span class="s">'deps'</span><span class="p">):</span>
        <span class="n">target_compile_jars</span> <span class="o">=</span> <span class="n">target</span><span class="p">[</span><span class="n">JavaInfo</span><span class="p">].</span><span class="n">full_compile_jars</span>
        <span class="n">dep_compile_jars</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">dep</span><span class="p">[</span><span class="n">ClassPathInfo</span><span class="p">].</span><span class="n">compile_jars</span>
            <span class="k">for</span> <span class="n">dep</span> <span class="ow">in</span> <span class="n">ctx</span><span class="p">.</span><span class="n">rule</span><span class="p">.</span><span class="n">attr</span><span class="p">.</span><span class="n">deps</span>
        <span class="p">]</span>
        <span class="n">all_compile_jars</span> <span class="o">=</span> <span class="p">[</span><span class="n">target_compile_jars</span><span class="p">]</span> <span class="o">+</span> <span class="n">dep_compile_jars</span>
        <span class="n">merged_depset</span> <span class="o">=</span> <span class="n">depset</span><span class="p">(</span><span class="n">transitive</span><span class="o">=</span><span class="n">all_compile_jars</span><span class="p">)</span>

        <span class="n">classpath_strings</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">jar</span> <span class="ow">in</span> <span class="n">merged_depset</span><span class="p">.</span><span class="n">to_list</span><span class="p">():</span>
            <span class="n">classpath_strings</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">jar</span><span class="p">.</span><span class="n">path</span><span class="p">)</span>

        <span class="n">output_file</span> <span class="o">=</span> <span class="n">ctx</span><span class="p">.</span><span class="n">actions</span><span class="p">.</span><span class="n">declare_file</span><span class="p">(</span><span class="s">"classpath.txt"</span><span class="p">)</span>
        <span class="n">ctx</span><span class="p">.</span><span class="n">actions</span><span class="p">.</span><span class="n">write</span><span class="p">(</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">output_file</span><span class="p">,</span>
            <span class="n">content</span> <span class="o">=</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">classpath_strings</span><span class="p">),</span>
            <span class="n">is_executable</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="p">[</span><span class="n">ClassPathInfo</span><span class="p">(</span>
            <span class="n">compile_jars</span> <span class="o">=</span> <span class="n">merged_depset</span>
            <span class="p">),</span>
            <span class="n">OutputGroupInfo</span><span class="p">(</span>
                <span class="n">compile_jars</span> <span class="o">=</span> <span class="n">depset</span><span class="p">([</span><span class="n">output_file</span><span class="p">])</span>
            <span class="p">)]</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">ClassPathInfo</span><span class="p">(</span><span class="n">compile_jars</span> <span class="o">=</span> <span class="n">depset</span><span class="p">())]</span>

<span class="n">classpath_aspect</span> <span class="o">=</span> <span class="n">aspect</span><span class="p">(</span>
    <span class="n">implementation</span> <span class="o">=</span> <span class="n">_classpath_aspect_impl</span><span class="p">,</span>
    <span class="c1"># attr_aspects is a list of rule attributes along
</span>    <span class="c1"># which the aspect propagates.
</span>    <span class="n">attr_aspects</span> <span class="o">=</span> <span class="p">[</span><span class="s">'deps'</span><span class="p">],</span>
<span class="p">)</span>
</code></pre></div></div>

<p>A <em>less documented</em> feature of Bazel is the “output groups” which you can see here we are
by specifying <code class="language-plaintext highlighter-rouge">OuputGroupInfo</code>. The idea here is that we can now specify our apect for any
label by using this command line invocation:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">&gt;</span><span class="w"> </span>bazel build //java/app <span class="nt">--aspects</span> defs.bzl%classpath_aspect <span class="se">\</span>
<span class="go">        --output_groups=compile_jars

INFO: Analyzed target //java/app:app (0 packages loaded, 0 targets configured).
INFO: Found 1 target...
Aspect //:defs.bzl%classpath_aspect of //java/app:app up-to-date:
  bazel-bin/java/app/classpath.txt

</span><span class="gp">&gt;</span><span class="w">  </span><span class="nb">cat </span>bazel-bin/java/app/classpath.txt
<span class="go">bazel-out/k8-fastbuild/bin/java/lib/liblib.jar
bazel-out/k8-fastbuild/bin/java/lib2/liblib2.jar⏎
</span></code></pre></div></div>

<p>That’s not all though! We can also create a rule that defines the labels provided must be of the type aspect.
This let’s us encode the build targets in our <code class="language-plaintext highlighter-rouge">BUILD</code> files themselves.</p>

<p>The rule itself is straightforward. For each label provided, it goes through the
items in the <code class="language-plaintext highlighter-rouge">compile_jars</code> depset and creates an output file which is the
concatenated new-line delimited list.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">_generate_classpath_rule_impl</span><span class="p">(</span><span class="n">ctx</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">dep</span> <span class="ow">in</span> <span class="n">ctx</span><span class="p">.</span><span class="n">attr</span><span class="p">.</span><span class="n">deps</span><span class="p">:</span>
        <span class="n">classpath_strings</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">jar</span> <span class="ow">in</span> <span class="n">dep</span><span class="p">[</span><span class="n">ClassPathInfo</span><span class="p">].</span><span class="n">compile_jars</span><span class="p">.</span><span class="n">to_list</span><span class="p">():</span>
            <span class="n">classpath_strings</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">jar</span><span class="p">.</span><span class="n">path</span><span class="p">)</span>
        <span class="n">output_file</span> <span class="o">=</span> <span class="n">ctx</span><span class="p">.</span><span class="n">actions</span><span class="p">.</span><span class="n">declare_file</span><span class="p">(</span><span class="s">"classpath.txt"</span><span class="p">)</span>
        <span class="n">ctx</span><span class="p">.</span><span class="n">actions</span><span class="p">.</span><span class="n">write</span><span class="p">(</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">output_file</span><span class="p">,</span>
            <span class="n">content</span> <span class="o">=</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">classpath_strings</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">DefaultInfo</span><span class="p">(</span><span class="n">files</span> <span class="o">=</span> <span class="n">depset</span><span class="p">([</span><span class="n">output_file</span><span class="p">]))]</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">DefaultInfo</span><span class="p">(</span><span class="n">files</span> <span class="o">=</span> <span class="bp">None</span><span class="p">)]</span>

<span class="n">generate_classpath_rule</span> <span class="o">=</span> <span class="n">rule</span><span class="p">(</span>
    <span class="n">implementation</span> <span class="o">=</span> <span class="n">_generate_classpath_rule_impl</span><span class="p">,</span>
    <span class="n">attrs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">'deps'</span> <span class="p">:</span> <span class="n">attr</span><span class="p">.</span><span class="n">label_list</span><span class="p">(</span><span class="n">aspects</span> <span class="o">=</span> <span class="p">[</span><span class="n">classpath_aspect</span><span class="p">]),</span>
    <span class="p">},</span>
<span class="p">)</span>
</code></pre></div></div>

<blockquote>
  <p>❗ There is a bit of duplication in the rule for generating the output file. We could have also
used the OutputGroupInfo and merged all the files together.</p>
</blockquote>

<p>In order to invoke this rule you define it in a <code class="language-plaintext highlighter-rouge">BUILD</code> file and give it the top-level
applications that you are working on.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">generate_classpath_rule</span><span class="p">(</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">"generate_classpath"</span><span class="p">,</span>
    <span class="n">deps</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s">"//java/app:app"</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>
</code></pre></div></div>

<p>🎉 We now have <strong>two</strong> pretty simple ways to generate the compile-time CLASSPATH for a label.
This can make integrations with IDEs a bit more straightforward if they don’t have a working Bazel plugin.</p>
              </div>
            </article>
        </main>

      <aside>
        <img src="logo.svg">
        <p>Last updated: 2025-01-12 20:49</p>
        <ul>
          
            <li>
              <a href="https://andreas.rammhold.de/">
                Andreas Rammhold
                </a>
              (<a href="https://andreas.rammhold.de/index.xml">feed</a>)
            </li>
          
            <li>
              <a href="https://blog.benjojo.co.uk/">
                benjojo blog
                </a>
              (<a href="https://blog.benjojo.co.uk/rss.xml">feed</a>)
            </li>
          
            <li>
              <a href="https://blog.ericv.me/atom.xml">
                Eric V's Blog
                </a>
              (<a href="https://blog.ericv.me/atom.xml">feed</a>)
            </li>
          
            <li>
              <a href="https://blog.koch.ro/feed.xml">
                Thomas Koch
                </a>
              (<a href="https://blog.koch.ro/feed.xml">feed</a>)
            </li>
          
            <li>
              <a href="https://elis.nu/blog/">
                ~elis/blog/ on Elis Hirwing
                </a>
              (<a href="https://elis.nu/blog/index.xml">feed</a>)
            </li>
          
            <li>
              <a href="https://eta.st/">
                eta.st
                </a>
              (<a href="https://eta.st/feed.xml">feed</a>)
            </li>
          
            <li>
              <a href="https://flokli.de/posts/">
                Posts on flokli
                </a>
              (<a href="https://flokli.de/posts/index.rss">feed</a>)
            </li>
          
            <li>
              <a href="https://fzakaria.com/feed.xml">
                Farid Zakaria’s Blog
                </a>
              (<a href="https://fzakaria.com/feed.xml">feed</a>)
            </li>
          
            <li>
              <a href="https://ghuntley.com/">
                Geoffrey Huntley
                </a>
              (<a href="https://ghuntley.com/rss/">feed</a>)
            </li>
          
            <li>
              <a href="https://leahneukirchen.org/blog">
                leah blogs
                </a>
              (<a href="https://leahneukirchen.org/blog/index.atom">feed</a>)
            </li>
          
            <li>
              <a href="https://marcus.means.no/https://marcus.means.no/">
                @’s marcus - marcus
                </a>
              (<a href="https://marcus.means.no/index.xml">feed</a>)
            </li>
          
            <li>
              <a href="https://tazjin/feed.atom">
                tazjin's interblag
                </a>
              (<a href="https://tazj.in/feed.atom">feed</a>)
            </li>
          
            <li>
              <a href="https://tech.j4m3s.eu/">
                j4m3s' tech blog
                </a>
              (<a href="https://tech.j4m3s.eu/index.xml">feed</a>)
            </li>
          
            <li>
              <a href="https://tvl.fyi/feed.atom">
                TVL blog
                </a>
              (<a href="https://tvl.fyi/feed.atom">feed</a>)
            </li>
          
        </ul>
      </aside>
    </div>
  </div>
  </body>
</html>
